{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a34884d-b8cc-4f2d-a947-4ccd738b1770",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LLMFS Load gpt2 weights into pytorch model\n",
    "Extracts from LLMFS to load weights into pytorch implementation of GPT2. Test different layers with simple values to compare with Tensorflow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168cf05e-54fa-4d66-bde1-fd714056cd77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f01e16b-0464-4a57-a47f-e9fc7dc9d9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.7.3\n",
      "numpy version: 1.26.3\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.1.1+cu121\n",
      "tensorflow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3fbe52c-ea43-4da8-9a97-71ee3a16018a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n",
    "def tldr(tensor):\n",
    "    return f\"{tensor.dtype} {tensor.shape} {tensor[0][0][:3]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8505e795-c2b5-42ea-9f3b-53110889a46d",
   "metadata": {},
   "source": [
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3567851a-451c-4820-820c-06b28e63d7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95d824b-cdda-4f3e-a878-b53e64588d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch04 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0bf60-6741-4b1d-9675-88da51bf170d",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dafb71fd-cdd6-4ab9-8c4e-217b29e0b306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for i in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        print(\"i=\", i, \"idx_cond=\", idx_cond)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        # print(\"  logits=\", logits.shape)\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "        # print(\"  idx_next=\", idx_next)\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f658e9-e550-49ba-9af6-ede4bdf1706b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 idx_cond= tensor([[6109, 3626, 6100,  345]])\n",
      "i= 1 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240]])\n",
      "i= 2 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686]])\n",
      "i= 3 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611]])\n",
      "i= 4 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876]])\n",
      "i= 5 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215]])\n",
      "i= 6 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196]])\n",
      "i= 7 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994]])\n",
      "i= 8 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994, 19513]])\n",
      "i= 9 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994, 19513, 31728]])\n",
      "i= 10 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994, 19513, 31728, 39042]])\n",
      "i= 11 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994, 19513, 31728, 39042,  5460]])\n",
      "i= 12 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994, 19513, 31728, 39042,  5460, 16454]])\n",
      "i= 13 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994, 19513, 31728, 39042,  5460, 16454, 38918]])\n",
      "i= 14 idx_cond= tensor([[ 6109,  3626,  6100,   345, 41240, 11686, 28611, 38876, 48215, 21196,\n",
      "           994, 19513, 31728, 39042,  5460, 16454, 38918,  9588]])\n",
      "Output text:\n",
      " Every effort moves you inferred rolleduint fabricationagos remarkably hereuced saints freewaylookOkayRand salary baseless\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538d86a-fb76-4b0c-b67e-061fe1121c95",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b85fccf-4103-41b8-9fcc-99a9fcef28f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "tqdm version: 4.66.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a82943-e2ef-404b-b547-2275f65d4ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 00:04:50.319964: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-27 00:04:50.799635: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-27 00:04:50.799733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-27 00:04:50.908184: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-27 00:04:51.141567: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-27 00:04:52.761018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26d6d7a-20c0-4acd-94d2-9cd72c01aaa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4691c14a-4cb4-4659-8dd1-7413ddfaf231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2eecc9-8e4d-41fb-8224-343191d3d3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78ab43a0-d4cb-46be-8034-67f5899d47b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1101  -0.03927  0.03311 ... -0.13637  0.01506  0.04532]\n",
      " [ 0.04034 -0.04862  0.04625 ...  0.08605  0.00254  0.04319]\n",
      " [-0.12746  0.04794  0.1841  ...  0.08992 -0.12972 -0.08786]\n",
      " ...\n",
      " [-0.04454 -0.05484  0.01226 ...  0.10435  0.09783 -0.06953]\n",
      " [ 0.18601  0.01666  0.04612 ... -0.09625  0.07848 -0.02246]\n",
      " [ 0.05135 -0.02769  0.04994 ...  0.00705  0.1552   0.12068]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "43abbca0-14e5-40d1-956c-070353e309a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "416ae36f-eff8-446c-aecf-c048f9e2424c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff4a3017-d70b-471e-a383-a908f70fa52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb7c80fa-1151-4d98-abff-266c7ad1b59c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92ff7031-eda4-4bef-811a-08f13d15ebd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 idx_cond= tensor([[6109, 3626, 6100,  345]], device='cuda:0')\n",
      "i= 1 idx_cond= tensor([[6109, 3626, 6100,  345,  355]], device='cuda:0')\n",
      "i= 2 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290]], device='cuda:0')\n",
      "i= 3 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355]], device='cuda:0')\n",
      "i= 4 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262]], device='cuda:0')\n",
      "i= 5 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021]],\n",
      "       device='cuda:0')\n",
      "i= 6 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460]],\n",
      "       device='cuda:0')\n",
      "i= 7 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467]],\n",
      "       device='cuda:0')\n",
      "i= 8 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566]],\n",
      "       device='cuda:0')\n",
      "i= 9 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566,\n",
      "          262]], device='cuda:0')\n",
      "i= 10 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566,\n",
      "          262,  886]], device='cuda:0')\n",
      "i= 11 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566,\n",
      "          262,  886,  286]], device='cuda:0')\n",
      "i= 12 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566,\n",
      "          262,  886,  286,  534]], device='cuda:0')\n",
      "i= 13 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566,\n",
      "          262,  886,  286,  534, 1210]], device='cuda:0')\n",
      "i= 14 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566,\n",
      "          262,  886,  286,  534, 1210, 4556]], device='cuda:0')\n",
      "i= 15 idx_cond= tensor([[6109, 3626, 6100,  345,  355, 1290,  355,  262, 1021,  460,  467, 1566,\n",
      "          262,  886,  286,  534, 1210, 4556, 1223]], device='cuda:0')\n",
      "i= 16 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237]],\n",
      "       device='cuda:0')\n",
      "i= 17 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534]], device='cuda:0')\n",
      "i= 18 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534,  1630]], device='cuda:0')\n",
      "i= 19 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534,  1630,  5202]], device='cuda:0')\n",
      "i= 20 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534,  1630,  5202,    13]], device='cuda:0')\n",
      "i= 21 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534,  1630,  5202,    13,  1081]], device='cuda:0')\n",
      "i= 22 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534,  1630,  5202,    13,  1081,   345]], device='cuda:0')\n",
      "i= 23 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534,  1630,  5202,    13,  1081,   345,   743]], device='cuda:0')\n",
      "i= 24 idx_cond= tensor([[ 6109,  3626,  6100,   345,   355,  1290,   355,   262,  1021,   460,\n",
      "           467,  1566,   262,   886,   286,   534,  1210,  4556,  1223, 48237,\n",
      "           534,  1630,  5202,    13,  1081,   345,   743, 12414]],\n",
      "       device='cuda:0')\n",
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea0a4afc-1dd7-4432-8909-3c895db4617d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=text_to_token_ids(\"Every effort moves you\", tokenizer)\n",
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ece601cf-f837-4906-8f24-8c2af7c95bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e40830-d5fc-4cab-90ef-2a7c29da3f5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2d0e8d5-3e81-4e22-b548-fb05cbc35b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "x_effort_emb: torch.float32 torch.Size([1, 4, 768]) tensor([ 0.0793, -0.2979,  0.0882], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device:\", device)\n",
    "gpt.to(\"cpu\");\n",
    "x_effort = torch.tensor([[6109, 3626, 6100, 345]])\n",
    "batch_size, seq_len = x_effort.shape\n",
    "\n",
    "tok_emb = gpt.tok_emb\n",
    "pos_emb = gpt.pos_emb\n",
    "tok_embeds = tok_emb(x_effort)\n",
    "pos_embeds = pos_emb(torch.arange(seq_len, device=x.device))\n",
    "x_effort_emb = tok_embeds + pos_embeds\n",
    "\n",
    "print(\"x_effort_emb:\", tldr(x_effort_emb))\n",
    "assert list(x_effort_emb.shape) == [1, 4, 768]\n",
    "assert np.allclose(x_effort_emb.detach()[0][0][:3], np.array([0.0793, -0.2979 ,  0.0882]), rtol=1e-4, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6733b3-2e0f-4ebd-a1a3-82ec626eaaf2",
   "metadata": {},
   "source": [
    "### Test norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0353e792-9856-4753-9345-8776a6b345b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dir(gpt.trf_blocks)\n",
    "# gpt.trf_blocks\n",
    "tb0_norm1 = gpt.trf_blocks.get_submodule(\"0.norm1\")\n",
    "# dir(tb0_norm1)\n",
    "x = torch.tensor(np.ones((1, 768) , dtype=np.float32))\n",
    "# tb0_norm1(x) # [-3.6773e-03,  2.7197e-02, -6.4041e-02\n",
    "\n",
    "# tb11_norm1 = gpt.trf_blocks.get_submodule(\"11.norm1\")\n",
    "#tb11_norm1(x) # [ 5.0957e-02,  5.3063e-03,  7.1952e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef79e625-9146-4b7f-a006-6d6cf9c24f29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0472, -0.1166, -0.0254,  ..., -0.0134, -0.0348,  0.0272],\n",
       "         [ 0.0059, -0.1736, -0.0962,  ...,  0.1672,  0.0370, -0.0667],\n",
       "         [-0.0523, -0.0529,  0.1247,  ...,  0.0327,  0.1120,  0.0014],\n",
       "         [-0.0406,  0.0055,  0.0506,  ..., -0.1240, -0.0731, -0.0745]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.trf_blocks.get_submodule(\"0.norm1\")(x_effort_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "379ce676-b3a0-46f8-84f4-a1e71eb22f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpt.trf_blocks.get_submodule(\"0.norm1\").shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a92dc61f-20fa-4ec6-abab-79c19b2d70ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test query layer, key layer, value layer\n",
    "x = torch.tensor(np.ones((1, 768) , dtype=np.float32))\n",
    "\n",
    "# block 0\n",
    "att0 = gpt.trf_blocks.get_submodule(\"0.att\")\n",
    "query0 = att0.get_submodule(\"W_query\")\n",
    "# query0(x) # [-1.3708e+01,  1.3385e+01,  1.4323e+01\n",
    "key0 = att0.get_submodule(\"W_key\")\n",
    "# key0(x) # [ 1.8049e-01, -1.4381e-01,  6.2964e-01\n",
    "value0 = att0.get_submodule(\"W_value\")\n",
    "# value0(x)\n",
    "proj0 = att0.get_submodule(\"out_proj\")\n",
    "# proj0(x)\n",
    "# proj0(value0(key0(query0(x)))) # [-2.3273e+01, -7.9272e+02,  5.6245e+02\n",
    "\n",
    "# block 11\n",
    "att11 = gpt.trf_blocks.get_submodule(\"11.att\")\n",
    "query11 = att11.get_submodule(\"W_query\")\n",
    "# query11(x) # [-5.4209e+00,  4.6236e+00,  4.5401e+00\n",
    "key11 = att11.get_submodule(\"W_key\")\n",
    "# key11(x) # [ 5.8911e+00, -3.3184e-01,  6.3656e-01\n",
    "value11 = att11.get_submodule(\"W_value\")\n",
    "# value11(x) # [-1.2480e+00, -3.0783e+00,  5.9679e+00\n",
    "\n",
    "proj11 = att11.get_submodule(\"out_proj\")\n",
    "# proj11(x) # [-4.1535e-01,  2.1763e+00,  4.7958e-01\n",
    "\n",
    "# proj11(value11(key11(query11(x)))) # [ 3.4414e+02,  4.9568e+02,  3.8639e+02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3dd75e1-34d1-402d-9d1c-0b5dd9728c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "x = torch.tensor(np.ones((1, 768) , dtype=np.float32))\n",
    "tb0_norm2 = gpt.trf_blocks.get_submodule(\"0.norm2\")\n",
    "# tb0_norm2(x)\n",
    "\n",
    "tb0_ff = gpt.trf_blocks.get_submodule(\"0.ff\")\n",
    "tb0_ff = gpt.trf_blocks.get_submodule(\"0.ff\")\n",
    "#tb0_ff(x) # [-1.6735e+01, -6.9883e+00,  4.1138e+00\n",
    "\n",
    "# tb11_norm2 = gpt.trf_blocks.get_submodule(\"11.norm2\")\n",
    "# tb11_norm2(x)\n",
    "tb11_ff = gpt.trf_blocks.get_submodule(\"11.ff\")\n",
    "#tb11_ff(x) # [ 1.3675e+01,  2.2839e+01, -1.7306e+01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "403f1ca2-f89d-42ba-9c66-d88b8c4ef487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb0_ff_linear1 = tb0_ff.layers[0]\n",
    "tb0_ff_gelu = tb0_ff.layers[1]\n",
    "# These 2 layers composed correspond to linear perceptron_layer with gelu activation function\n",
    "# tb0_ff_gelu(tb0_ff_linear1(x)) # [ 3.5592, -0.1381, -0.1655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7afb8044-71ad-437d-a19c-debe043c4cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb0_ff_linear2 = tb0_ff.layers[2]\n",
    "# tb0_ff_linear2(x) # How to test??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49beef1f-bd55-4b44-b777-fb89e9fe6e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(np.ones((1, 768) , dtype=np.float32))\n",
    "final_norm = gpt.final_norm\n",
    "# final_norm(x) # [ 1.0872e-03,  3.6529e-02, -6.7296e-02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef32daa8-5c32-4c07-ae37-8e05b6dda54f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(np.ones((1, 768) , dtype=np.float32))\n",
    "out_head = gpt.out_head\n",
    "out_head\n",
    "#out_head(x) # [ 0.3766,  3.4404,  2.0287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79d4dad9-e477-43c1-bc33-fa03f2d6bde9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-32.9011, -31.2024, -34.6623,  ..., -39.4868, -39.8732, -32.2387],\n",
       "         [-55.5208, -53.4286, -56.4767,  ..., -68.1539, -66.7709, -58.6006],\n",
       "         [-61.7969, -60.5386, -59.5503,  ..., -75.3206, -72.7731, -65.5706]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trivial = torch.tensor([[1, 2, 3]])\n",
    "gpt(x_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "454417d5-c110-434d-a176-4e5aa1c7e93f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:\n",
      " tensor([[[ -35.5820,  -34.9804,  -38.4522,  ...,  -42.0959,  -41.8533,\n",
      "           -35.5966],\n",
      "         [ -76.9601,  -76.6970,  -81.9309,  ...,  -88.7984,  -86.7631,\n",
      "           -78.9627],\n",
      "         [-125.3487, -126.2704, -135.0948,  ..., -132.3173, -135.2544,\n",
      "          -127.6511],\n",
      "         [-136.6002, -137.3804, -146.5556,  ..., -148.2978, -147.2155,\n",
      "          -139.5677]]], grad_fn=<UnsafeViewBackward0>)\n",
      "logits:\n",
      " tensor([[-136.6002, -137.3804, -146.5556,  ..., -148.2978, -147.2155,\n",
      "         -139.5677]], grad_fn=<SliceBackward0>)\n",
      "logits[-1]:\n",
      " tensor([-136.6002, -137.3804, -146.5556,  ..., -148.2978, -147.2155,\n",
      "        -139.5677], grad_fn=<SelectBackward0>)\n",
      "probas:\n",
      " tensor([[1.6013e-03, 7.3391e-04, 7.6013e-08,  ..., 1.3313e-08, 3.9292e-08,\n",
      "         8.2357e-05]], grad_fn=<SoftmaxBackward0>)\n",
      "idx_next:\n",
      " tensor([2651])\n"
     ]
    }
   ],
   "source": [
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "idx = text_to_token_ids(\"Every effort moves you\", tokenizer)\n",
    "\n",
    "# x # tensor([[6109, 3626, 6100,  345]])\n",
    "idx_cond = idx[:, -context_size:]\n",
    "idx_cond # tensor([[6109, 3626, 6100,  345]])\n",
    "logits = gpt(idx)\n",
    "print(\"logits:\\n\", logits)\n",
    "logits = logits[:, -1, :]\n",
    "print(\"logits:\\n\", logits)\n",
    "print(\"logits[-1]:\\n\", logits[-1])\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"probas:\\n\", probas)\n",
    "idx_next = torch.argmax(probas, dim=-1)\n",
    "print(\"idx_next:\\n\", idx_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e222a5a-43ef-4049-8018-c91dea99856c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 idx_cond= tensor([[6109, 3626, 6100,  345]], device='cuda:0')\n",
      "i= 1 idx_cond= tensor([[6109, 3626, 6100,  345, 2651]], device='cuda:0')\n",
      "i= 2 idx_cond= tensor([[6109, 3626, 6100,  345, 2651,   13]], device='cuda:0')\n",
      "i= 3 idx_cond= tensor([[6109, 3626, 6100,  345, 2651,   13,  198]], device='cuda:0')\n",
      "i= 4 idx_cond= tensor([[6109, 3626, 6100,  345, 2651,   13,  198,  198]], device='cuda:0')\n",
      "tensor([[6109, 3626, 6100,  345, 2651,   13,  198,  198,  464]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gpt.to(device);\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=5,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    ")\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0645b7d8-c307-433d-b5bf-276b8b739878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you forward.\n",
      "\n",
      "The first step is to understand\n"
     ]
    }
   ],
   "source": [
    "gpt.to(\"cpu\")\n",
    "start_context = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=256\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a3bb9da-c422-46b0-a9a0-91d6c2bdbb81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a4510c6-9ef6-41d6-a631-f0e9f477d916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4599,  2.6167,  3.0796,  ..., -3.7902, -0.3126, -3.3074],\n",
       "         [-0.9835,  2.6840,  1.8440,  ..., -0.2896, -3.1945, -1.4446],\n",
       "         [-0.1488,  2.3184,  1.7861,  ..., -1.1154, -3.3635, -2.2503]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "gpt.to(\"cpu\");\n",
    "# x = torch.tensor([[1]])\n",
    "x_trivial = torch.tensor([[1, 2, 3]])\n",
    "\n",
    "tok_embeds = tok_emb(x_trivial)\n",
    "pos_embeds = pos_emb(torch.arange(seq_len, device=x.device))\n",
    "x_embedded = tok_embeds + pos_embeds\n",
    "x_embedded # [ 2.1520e-02, -2.4603e-01,  5.0275e-02\n",
    "att0 = gpt.trf_blocks.get_submodule(\"0.att\")\n",
    "query0 = att0.get_submodule(\"W_query\")\n",
    "query0(x_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2f4025d-b22a-4aa6-8bd6-ad47d9cc5117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm10 = gpt.trf_blocks.get_submodule(\"0.norm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efda4809-26e4-439b-b22a-b60da851bd90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x01: [ 0.00984593 -0.09290446 -0.04286208]\n"
     ]
    }
   ],
   "source": [
    "x01 = norm10(x_embedded)\n",
    "print('x01:', x01[0][0][:3].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0f8b199-d82c-444e-b211-b475eab44b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x02: [0.3328247  0.08782893 0.18114716]\n"
     ]
    }
   ],
   "source": [
    "att0 = gpt.trf_blocks.get_submodule(\"0.att\")\n",
    "x02 = att0(x01)\n",
    "print('x02:', x02[0][0][:3].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785f0d7-7f61-49bc-8575-73f50b6a7c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
