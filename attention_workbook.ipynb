{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7be2b182-9bc2-414a-b334-44d3a0854cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc8d4f8b-6c43-4128-bc96-3fe01b01bead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeds = [\n",
    "    [0.43, 0.15, 0.89], # Your \n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts\n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55]  # step\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "463496dd-4fc5-4db9-9e45-344eadb42537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "477ebbdb-5744-430e-9dd8-d205c7b87e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "467bca1c-5772-4c3f-a07c-e818daeedfdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5faa9-1675-406f-9242-d0c63a758db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# torch.manual_seed(123)\n",
    "# d_in = 3\n",
    "# d_out = 2\n",
    "# q_weight     = nn.Parameter(torch.rand(d_in, d_out))\n",
    "# key_weight   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "# value_weight = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "# print(\"q_weight:\\n\", q_weight)\n",
    "\n",
    "# print(\"key_weight:\\n\", key_weight)\n",
    "\n",
    "# print(\"value_weight:\\n\", value_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "408ac255-b144-43be-91b8-91bd6fda05a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        # print(\"keys:\", keys)\n",
    "        queries = x @ self.W_query\n",
    "        # print(\"queries:\", queries)\n",
    "        values = x @ self.W_value\n",
    "        # print(\"values:\", values) \n",
    "        \n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        # print(\"attn_scores:\", attn_scores) \n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        # print(\"attn_weights:\", attn_weights) \n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "043d247d-a5c1-4598-9711-5bf3c528271f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sa_v1.W_query\n",
    "# sa_v1.W_key\n",
    "# sa_v1.W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d4c62601-7350-4e18-b5fa-d7920f48c88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6383d4cb-e363-4cab-96ce-2b942131bb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor([0.43 0.15 0.89], shape=(3,), dtype=float32)\n",
      "1 tf.Tensor([0.55 0.87 0.66], shape=(3,), dtype=float32)\n",
      "2 tf.Tensor([0.57 0.85 0.64], shape=(3,), dtype=float32)\n",
      "3 tf.Tensor([0.22 0.58 0.33], shape=(3,), dtype=float32)\n",
      "4 tf.Tensor([0.77 0.25 0.1 ], shape=(3,), dtype=float32)\n",
      "5 tf.Tensor([0.05 0.8  0.55], shape=(3,), dtype=float32)\n",
      "attn_scores_2: tf.Tensor([0.95440006 1.4950001  1.4754001  0.8434     0.707      1.0865    ], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.constant(embeds)\n",
    "query = inputs[1]\n",
    "attn_scores_2 = np.empty(inputs.shape[0])\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    print(i, x_i)\n",
    "    attn_scores_2[i] = x_i.numpy() @ query.numpy()\n",
    "attn_scores_2 = tf.constant(attn_scores_2, dtype=tf.float32)    \n",
    "print(\"attn_scores_2:\", attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "24cea333-30e2-418f-ba86-5172eb617c79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights_2: tf.Tensor([0.13854761 0.23789133 0.23327404 0.1239916  0.10818188 0.15811363], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# attn_weights_2 is softmax of attn_scores_2\n",
    "attn_weights_2 = tf.nn.softmax(attn_scores_2)\n",
    "print(\"attn_weights_2:\", attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0df0d78a-5abc-4dfa-9ad9-7cf2f02f1306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[0.43, 0.15, 0.89],\n",
       "       [0.55, 0.87, 0.66],\n",
       "       [0.57, 0.85, 0.64],\n",
       "       [0.22, 0.58, 0.33],\n",
       "       [0.77, 0.25, 0.1 ],\n",
       "       [0.05, 0.8 , 0.55]], dtype=float32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8c12e896-1114-400a-9e97-c7892c038bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.44186577, 0.65148205, 0.56830895], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "context_vec2 = tf.tensordot(attn_weights_2, inputs, axes=1)\n",
    "context_vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "675421df-8e1f-4477-a3a4-def3b4e9b21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b8a00172-d503-4ee9-8881-5b8b2b72832c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttenion_v0(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        keys = x\n",
    "        queries = x\n",
    "        values = x\n",
    "\n",
    "        attn_scores = tf.matmul(queries, keys, transpose_b=True)\n",
    "        attn_weights = tf.nn.softmax(attn_scores)\n",
    "        all_context_vecs = tf.matmul(attn_weights, values, transpose_b=False)\n",
    "        return all_context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "71b8491e-9082-4c1e-a258-255c995c81f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[0.44205937, 0.5930985 , 0.578989  ],\n",
       "       [0.4418658 , 0.65148205, 0.568309  ],\n",
       "       [0.44312754, 0.6495946 , 0.5670731 ],\n",
       "       [0.43038973, 0.6298281 , 0.55102706],\n",
       "       [0.46710175, 0.5909928 , 0.5265966 ],\n",
       "       [0.41772443, 0.65032315, 0.56453526]], dtype=float32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa = SelfAttenion_v0()\n",
    "sa(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c5d59ad0-ab44-44d9-9599-e91cfd93f2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dd7cd71-53d4-4bfe-87f7-8c9d32831805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weights from LLMFS listing 3.1\n",
    "qw = np.array([[0.2961, 0.5166],\n",
    "        [0.2517, 0.6886],\n",
    "        [0.0740, 0.8665]], dtype=np.float32)\n",
    "kw = np.array([[0.1366, 0.1025],\n",
    "        [0.1841, 0.7264],\n",
    "        [0.3153, 0.6871]], dtype=np.float32)\n",
    "vw = np.array([[0.0756, 0.1966],\n",
    "        [0.3164, 0.4017],\n",
    "        [0.1186, 0.8274]], dtype=np.float32)\n",
    "# dummy_input = tf.zeros(shape=(6, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "524961da-da8d-488e-829f-015954ae1556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corresponds to LLMFS listing 3.2\n",
    "class SelfAttenion_v1(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        b = 0\n",
    "        self.query_layer = tf.keras.layers.Dense(units=2, activation=None, name=f\"query-{b}\", use_bias=False)\n",
    "        self.query_layer.build((None, 3 ))\n",
    "        self.key_layer = tf.keras.layers.Dense(units=2, activation=None, name=f\"key-{b}\", use_bias=False)\n",
    "        self.key_layer.build((None, 3))\n",
    "        self.value_layer = tf.keras.layers.Dense(units=2, activation=None, name=f\"value-{b}\", use_bias=False)\n",
    "        self.value_layer.build((None, 3))\n",
    "    def __call__(self, x):\n",
    "        keys = self.key_layer(x)\n",
    "        # print(\"keys:\", keys)\n",
    "        queries = self.query_layer(x)\n",
    "        # print(\"queries:\", queries)\n",
    "        values = self.value_layer(x)\n",
    "        # print(\"values:\", values)\n",
    "        attn_scores = tf.matmul(queries, keys, transpose_b=True)\n",
    "        # print(\"attn_scores:\", attn_scores)\n",
    "        attn_weights = tf.nn.softmax(attn_scores / keys.shape[-1]**0.5, axis=-1)\n",
    "        # print(\"attn_weights:\", attn_weights)\n",
    "        all_context_vecs = tf.matmul(attn_weights, values, transpose_b=False)\n",
    "        return all_context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d0d07a0a-90f5-4072-bdab-5032862e044d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sa = SelfAttenion_v1()\n",
    "sa.query_layer.set_weights([qw])\n",
    "sa.key_layer.set_weights([kw])\n",
    "sa.value_layer.set_weights([vw])\n",
    "# sa.query_layer.get_config()\n",
    "\n",
    "# sa.query_layer(dummy_input)\n",
    "# sa.query_layer.set_weights([qw])\n",
    "# sa.key_layer.set_weights([kw])\n",
    "# sa.value_layer.set_weights([vw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6fe02ebd-8983-47f8-a278-52cfa17d8f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[0.2995769 , 0.8052748 ],\n",
       "       [0.30609584, 0.8209922 ],\n",
       "       [0.30577675, 0.82025766],\n",
       "       [0.29476127, 0.7938287 ],\n",
       "       [0.29270154, 0.7890473 ],\n",
       "       [0.29900536, 0.8039986 ]], dtype=float32)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.constant(embeds)\n",
    "sa(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39456efc-8ba2-4089-9b63-de4710fe006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fec24e54-5fb6-4c53-8303-f0a1ea0de3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_causal_mask(seq_len):\n",
    "    \"\"\"\n",
    "    Generates a boolean causal mask of shape (seq_len, seq_len).\n",
    "    \"\"\"\n",
    "    # Create a tensor of shape (seq_len, seq_len)\n",
    "    mask = tf.ones((seq_len, seq_len), dtype=tf.bool)\n",
    "    \n",
    "    # Use band_part to keep only the lower triangle (including the diagonal)\n",
    "    # num_lower: -1 means keep all lower-triangular parts\n",
    "    # num_upper: 0 means keep 0 upper-triangular parts (only the diagonal)\n",
    "    lower_triangular = tf.linalg.band_part(\n",
    "        mask, \n",
    "        num_lower=-1, \n",
    "        num_upper=0\n",
    "    )\n",
    "    \n",
    "    return lower_triangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2a5f1096-85b3-4d5b-bc0c-75375f4699b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[-0.e+00, -1.e+09, -1.e+09, -1.e+09, -1.e+09, -1.e+09],\n",
       "       [-0.e+00, -0.e+00, -1.e+09, -1.e+09, -1.e+09, -1.e+09],\n",
       "       [-0.e+00, -0.e+00, -0.e+00, -1.e+09, -1.e+09, -1.e+09],\n",
       "       [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+09, -1.e+09],\n",
       "       [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+09],\n",
       "       [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_mask = create_causal_mask(6)\n",
    "additive_mask = 1.0 - tf.cast(causal_mask, dtype=tf.float32)\n",
    "additive_mask\n",
    "large_negative_value = -1e9 \n",
    "additive_mask_applied = additive_mask * large_negative_value\n",
    "additive_mask_applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0767607e-a093-4ea5-b8a2-98c83c04c8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corresponds to LLMFS listing 3.3\n",
    "class CausalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        b = 0\n",
    "        self.query_layer = tf.keras.layers.Dense(units=2, activation=None, name=f\"query-{b}\", use_bias=False)\n",
    "        self.query_layer.build((None, 3 ))\n",
    "        self.key_layer = tf.keras.layers.Dense(units=2, activation=None, name=f\"key-{b}\", use_bias=False)\n",
    "        self.key_layer.build((None, 3))\n",
    "        self.value_layer = tf.keras.layers.Dense(units=2, activation=None, name=f\"value-{b}\", use_bias=False)\n",
    "        self.value_layer.build((None, 3))\n",
    "    def __call__(self, x):\n",
    "        # b, \n",
    "        num_tokens, d_in = x.shape\n",
    "        keys = self.key_layer(x)\n",
    "        # print(\"keys:\", keys)\n",
    "        queries = self.query_layer(x)\n",
    "        # print(\"queries:\", queries)\n",
    "        values = self.value_layer(x)\n",
    "        # print(\"values:\", values)\n",
    "        # attn_scores = tf.matmul(queries, keys, transpose_b=True)\n",
    "        # coefficients = tf.matmul(queries, tf.transpose(keys, perm=[0,2,1]))\n",
    "        coefficients = tf.matmul(queries, tf.transpose(keys, perm=[1,0]))\n",
    "        print(\"coefficients:\", coefficients)\n",
    "\n",
    "        # mask = tf.linalg.band_part(tf.ones((num_tokens, num_tokens)), -1, 0)\n",
    "        # print(\"mask:\", mask)\n",
    "        attn_scores = coefficients + additive_mask_applied\n",
    "        print(\"attn_scores:\", attn_scores)\n",
    "        attn_weights = tf.nn.softmax(attn_scores / keys.shape[-1]**0.5, axis=-1)\n",
    "        # print(\"attn_weights:\", attn_weights)\n",
    "        all_context_vecs = tf.matmul(attn_weights, values, transpose_b=False)\n",
    "        return all_context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4b23a440-3daf-47f5-950b-3b12f9191f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6, 3), dtype=float32, numpy=\n",
       "array([[[0.43, 0.15, 0.89],\n",
       "        [0.55, 0.87, 0.66],\n",
       "        [0.57, 0.85, 0.64],\n",
       "        [0.22, 0.58, 0.33],\n",
       "        [0.77, 0.25, 0.1 ],\n",
       "        [0.05, 0.8 , 0.55]],\n",
       "\n",
       "       [[0.43, 0.15, 0.89],\n",
       "        [0.55, 0.87, 0.66],\n",
       "        [0.57, 0.85, 0.64],\n",
       "        [0.22, 0.58, 0.33],\n",
       "        [0.77, 0.25, 0.1 ],\n",
       "        [0.05, 0.8 , 0.55]]], dtype=float32)>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.constant(embeds)\n",
    "batch = tf.stack((inputs, inputs))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d6faa04d-8631-4bd0-af7a-2aceb3b3154e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ca = CausalAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a4f07456-6ffc-4420-bdbd-062679de4321",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients: tf.Tensor(\n",
      "[[-0.19195148 -0.36451432 -0.38414305 -0.14244172 -0.62964225  0.03199355]\n",
      " [-0.33032215 -0.6104431  -0.63550246 -0.2594384  -0.90808207 -0.04208406]\n",
      " [-0.32210398 -0.5963464  -0.6213471  -0.25205636 -0.8968554  -0.03474403]\n",
      " [-0.20046927 -0.36579722 -0.37858456 -0.16142553 -0.50239176 -0.05251247]\n",
      " [-0.08335634 -0.17448942 -0.19140114 -0.04808448 -0.4422074   0.10734363]\n",
      " [-0.29117894 -0.5230913  -0.5374055  -0.24146162 -0.6440127  -0.12372647]], shape=(6, 6), dtype=float32)\n",
      "attn_scores: tf.Tensor(\n",
      "[[-1.9195148e-01 -1.0000000e+09 -1.0000000e+09 -1.0000000e+09\n",
      "  -1.0000000e+09 -1.0000000e+09]\n",
      " [-3.3032215e-01 -6.1044312e-01 -1.0000000e+09 -1.0000000e+09\n",
      "  -1.0000000e+09 -1.0000000e+09]\n",
      " [-3.2210398e-01 -5.9634638e-01 -6.2134713e-01 -1.0000000e+09\n",
      "  -1.0000000e+09 -1.0000000e+09]\n",
      " [-2.0046927e-01 -3.6579722e-01 -3.7858456e-01 -1.6142553e-01\n",
      "  -1.0000000e+09 -1.0000000e+09]\n",
      " [-8.3356343e-02 -1.7448942e-01 -1.9140114e-01 -4.8084475e-02\n",
      "  -4.4220740e-01 -1.0000000e+09]\n",
      " [-2.9117894e-01 -5.2309132e-01 -5.3740549e-01 -2.4146162e-01\n",
      "  -6.4401269e-01 -1.2372647e-01]], shape=(6, 6), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[-0.7828562 ,  0.42228222],\n",
       "       [-0.9191122 ,  0.3110891 ],\n",
       "       [-0.9676956 ,  0.2567558 ],\n",
       "       [-0.86749935,  0.22659169],\n",
       "       [-0.83010334,  0.08190385],\n",
       "       [-0.79709584,  0.17433873]], dtype=float32)>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68485b1f-40e5-4ab5-a3f7-10c58b34b2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
