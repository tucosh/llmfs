{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9bc820-b134-4b4a-8185-5d62a4db439c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc557e04-e1f5-4345-a5e0-7c742b5103ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f059e1-f3b0-441c-bf9a-bfea5ba4c244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_print(text, condition):\n",
    "    \"\"\"Prints text in green if condition is True, or red if condition is False.\"\"\"\n",
    "    # ANSI escape code for Red\n",
    "    RED = '\\033[91m'\n",
    "    # ANSI escape code for Green\n",
    "    GREEN = '\\033[92m'\n",
    "    # ANSI escape code to reset color\n",
    "    ENDC = '\\033[0m'    \n",
    "    if condition:\n",
    "        print(f\"{GREEN}{text}{ENDC}\")\n",
    "    else:\n",
    "        print(f\"{RED}{text}{ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297a2b6a-c63e-466a-ae31-bd2767036ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load weights into a \"params\" dict\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings) -> dict[str: Any]:\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04209f54-0538-475a-8e27-fcba62a53cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "settings = {\"n_layer\": 12}\n",
    "\n",
    "model_dir=\"ch05/01_main-chapter-code/gpt2/124M\"\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "# params.keys() # dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47029e76-015f-49d1-8d48-c7a0b4576e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb = tf.keras.layers.Embedding(input_dim=4, output_dim=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003c2e0c-e851-44c4-996c-1cefef35d6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 4), dtype=float32, numpy=\n",
       "array([[ 0.02903571,  0.0076947 , -0.03703507, -0.02101977],\n",
       "       [-0.01560724, -0.03536775,  0.0268792 , -0.02861235],\n",
       "       [-0.00908197, -0.02716467,  0.01001495,  0.01660894],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1,2,3,4,5,6])\n",
    "emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74d27da7-9734-44be-9711-e8f9e2008c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config124M = {'n_embd': 768, 'n_vocab': 50257, 'n_ctx': 1024, 'n_layer': 12, 'n_head': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb04471b-0e97-4222-a904-9ca7aded8d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b2d91f-713e-4c9c-b4f5-02fcc1a5a373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# w = np.array(params['wte'])\n",
    "word_emb = tf.keras.layers.Embedding(input_dim=50257, output_dim=768, weights=[np.array(params['wte'])])\n",
    "pos_emb = tf.keras.layers.Embedding(input_dim=1024, output_dim=768, weights=[np.array(params['wpe'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159bb0ac-6870-4ba8-b58c-1af8c85bd6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 768)\n",
      "(1024, 768)\n",
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X1 = tf.constant([[1]])\n",
    "x_trivial = tf.constant([[1, 2, 3]])\n",
    "we = word_emb(X1)\n",
    "print(we.shape)\n",
    "pe = pos_emb(tf.range(1024))\n",
    "print(pe.shape) # 1, \n",
    "e = we + pe # [ 2.1520e-02, -2.4603e-01,  5.0275e-02\n",
    "\n",
    "test_values = e[0][0][:3].numpy()\n",
    "expected_values = np.array([ 2.1520e-02, -2.4603e-01,  5.0275e-02])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1921380b-90a9-4831-b163-4779621861f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x_trivial = tf.constant([[1, 2, 3]])\n",
    "we = word_emb(x_trivial) # TensorShape([1, 3, 768])\n",
    "pe = pos_emb(tf.range(1024)) # .shape # TensorShape([1024, 768])\n",
    "pe_corrected = pe[:3, :]\n",
    "x = we + pe_corrected # [ 0.02151961, -0.24603364,  0.05027542\n",
    "test_values = x[0][0][:3].numpy()\n",
    "expected_values = np.array([ 0.02151961, -0.24603364,  0.05027542])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88918234-55cb-4afd-b2bd-3a8c2ff496ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4def0c-930e-45b1-897f-5dc805f80002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "b=0\n",
    "norm1_beta = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "norm1_gamma = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "norm1 = tf.keras.layers.LayerNormalization(beta_initializer=norm1_beta, gamma_initializer=norm1_gamma, name=f\"norm1-{b}\")\n",
    "\n",
    "norm2_beta = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "norm2_gamma = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "norm2 = tf.keras.layers.LayerNormalization(beta_initializer=norm2_beta, gamma_initializer=norm2_gamma, name=f\"norm2-{b}\")\n",
    "\n",
    "final_norm_beta = tf.keras.initializers.Constant(params[\"b\"])\n",
    "final_norm_gamma = tf.keras.initializers.Constant(params[\"g\"])\n",
    "final_norm = tf.keras.layers.LayerNormalization(beta_initializer=final_norm_beta, gamma_initializer=final_norm_gamma, name=f\"final-norm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a225ef-d0b7-45d3-971e-897b3b1ce7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mnorm1 test_result: True\u001b[0m\n",
      "\u001b[92mnorm2 test_result: True\u001b[0m\n",
      "\u001b[92mfinal_norm test_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x = np.ones((1, 768) , dtype=np.float32)\n",
    "\n",
    "test_values = norm1(x)[0][:3].numpy()\n",
    "expected_values = np.array([-3.6773e-03,  2.7197e-02, -6.4041e-02])\n",
    "test_result = np.allclose(test_values, expected_values)\n",
    "color_print(f\"norm1 test_result: {test_result}\", test_result)\n",
    "\n",
    "test_values = norm2(x)[0][:3].numpy()\n",
    "expected_values = np.array([ 4.2478e-02,  3.2627e-02,  4.4881e-03])\n",
    "test_result = np.allclose(test_values, expected_values)\n",
    "color_print(f\"norm2 test_result: {test_result}\", test_result)\n",
    "\n",
    "test_values = final_norm(x)[0][:3].numpy()\n",
    "expected_values = np.array([ 1.0872e-03,  3.6529e-02, -6.7296e-02])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"final_norm test_result: {test_result}\", test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "799f27f8-3593-4bef-9594-b442c11fbaf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['wte'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c78b62d2-9855-41b3-9934-089c2ef557ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d8f8f19-58a4-476d-ba38-bb192880b5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.ones((1, 768) , dtype=np.float32)\n",
    "out_head_layer = tf.keras.layers.Dense(units=50257, activation=None, use_bias=False, name=f\"out-head\")\n",
    "out_head_layer.build((50257, 768))\n",
    "out_head_layer.set_weights([params['wte'].T])\n",
    "# out_head_layer.weights\n",
    "# out_head_layer.get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97898185-55f1-44cb-b4dc-185d3a73410c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b=0\n",
    "q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "\n",
    "query_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"query-{b}\")\n",
    "query_layer.build((None, 768))\n",
    "key_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"key-{b}\")\n",
    "key_layer.build((None, 768))\n",
    "value_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"value-{b}\")\n",
    "value_layer.build((None, 768))\n",
    "proj_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"proj-{b}\")\n",
    "proj_layer.build((None, 768))\n",
    "\n",
    "# WORK ON THESE!\n",
    "perceptron_layer = tf.keras.layers.Dense(units=3072, activation=tf.keras.activations.gelu, name=f\"mlp-perceptron-{b}\")\n",
    "perceptron_layer.build((3072, 768))\n",
    "mlp_proj_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"mlp-proj-{b}\")\n",
    "mlp_proj_layer.build((None, 3072))\n",
    "\n",
    "query_layer.set_weights([q_w, q_b])\n",
    "key_layer.set_weights([k_w, k_b])\n",
    "value_layer.set_weights([v_w, v_b])\n",
    "proj_layer.set_weights([params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"], params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]])\n",
    "perceptron_layer.set_weights([params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"], params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]])\n",
    "mlp_proj_layer.set_weights([params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"], params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ded66d9e-b263-4646-8ca3-8d7ed548c4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# query_layer(x) # [-1.3708e+01,  1.3385e+01,  1.4323e+01\n",
    "test_values = query_layer(x)[0][:3].numpy()\n",
    "expected_values = np.array([-1.3708e+01,  1.3385e+01,  1.4323e+01])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4488a3f5-b35b-457d-844c-a90a3a0559b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_values = key_layer(x)[0][:3].numpy()\n",
    "expected_values = np.array([ 1.8049e-01, -1.4381e-01,  6.2964e-01])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bebb7fc-85c3-4f60-89b0-d00fcd41e988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_values = value_layer(x)[0][:3].numpy()\n",
    "expected_values = np.array([-6.1687e-02, -1.3786e-01, -3.0145e-01])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d3ce160-9745-460c-8b8d-c7332a0c79a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_values = proj_layer(x)[0][:3].numpy()\n",
    "expected_values = np.array([-9.7561e+00, -1.7296e+01, -6.7800e-01])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79f0733e-087b-4bde-b19d-05abf1d5761d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Compose proj_layer, value_layer, key_layer, query_layer\n",
    "test_values = proj_layer(value_layer(key_layer(query_layer(x))))[0][:3].numpy() # [-2.3273e+01, -7.9272e+02,  5.6245e+02\n",
    "expected_values = np.array([-2.3273e+01, -7.9272e+02,  5.6245e+02])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f9a2b49-c928-41cd-9a3d-5a6af50f60b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_values =  perceptron_layer(x)[0][:3].numpy()  # [-1.6735e+01, -6.9883e+00,  4.1138e+00 \n",
    "expected_values = np.array([ 3.5592, -0.1381, -0.1655])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e52d2a6-4bad-4745-9f57-5199ebb1a90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_values =  mlp_proj_layer(x)[0][:3].numpy()  # How to test?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "102ec1dc-5950-4575-b97b-ba11e68ef515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Compose perceptron_layer, mlp_proj_layer\n",
    "test_values =  mlp_proj_layer(perceptron_layer(x))[0][:3].numpy()  # [-1.6735e+01, -6.9883e+00,  4.1138e+00 \n",
    "expected_values = np.array([-1.6735e+01, -6.9883e+00,  4.1138e+00])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b66eeda-7138-42e6-9f63-68433a393b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mtest_result: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_values = out_head_layer(x)[0][:3].numpy()\n",
    "expected_values = np.array([ 0.3766,  3.4404,  2.0287])\n",
    "test_result = np.allclose(test_values, expected_values, rtol=1e-3, atol=1e-3)\n",
    "color_print(f\"test_result: {test_result}\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4cc77c9-9f12-42b1-b153-3f63234c4011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class GPT21(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, config, name=None, trainable=True, dtype=None):\n",
    "        super().__init__(name=name)\n",
    "        self.trainable = trainable\n",
    "        self.embedding_size=config['n_embd']\n",
    "        self.vocab_size=config['n_vocab']\n",
    "        self.max_position_length=config['n_ctx']\n",
    "        self.blocks_num = config[\"n_layer\"]\n",
    "\n",
    "        self.word_emb = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, weights=[np.array(params['wte'])], name=\"word_emb\")\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=self.max_position_length, output_dim=self.embedding_size, weights=[np.array(params['wpe'])], name=\"pos_emb\")\n",
    "\n",
    "        self.blocks = []\n",
    "        self.blocks_num = config[\"n_layer\"]\n",
    "        for b in range(self.blocks_num):\n",
    "            norm1_beta = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "            norm1_gamma = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "            norm1 = tf.keras.layers.LayerNormalization(beta_initializer=norm1_beta, gamma_initializer=norm1_gamma, name=f\"norm1-{b}\")\n",
    "\n",
    "            norm2_beta = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "            norm2_gamma = tf.keras.initializers.Constant(params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "            norm2 = tf.keras.layers.LayerNormalization(beta_initializer=norm2_beta, gamma_initializer=norm2_gamma, name=f\"norm2-{b}\")\n",
    "\n",
    "            q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "            q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "\n",
    "            query_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"query-{b}\")\n",
    "            query_layer.build((None, 768))\n",
    "            key_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"key-{b}\")\n",
    "            key_layer.build((None, 768))\n",
    "            value_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"value-{b}\")\n",
    "            value_layer.build((None, 768))\n",
    "            proj_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"proj-{b}\")\n",
    "            proj_layer.build((None, 768))\n",
    "\n",
    "            perceptron_layer = tf.keras.layers.Dense(units=3072, activation=tf.keras.activations.gelu, name=f\"mlp-perceptron-{b}\")\n",
    "            perceptron_layer.build((3072, 768))\n",
    "            mlp_proj_layer = tf.keras.layers.Dense(units=768, activation=None, name=f\"mlp-proj-{b}\")\n",
    "            mlp_proj_layer.build((None, 3072))\n",
    "\n",
    "            query_layer.set_weights([q_w, q_b])\n",
    "            key_layer.set_weights([k_w, k_b])\n",
    "            value_layer.set_weights([v_w, v_b])\n",
    "            proj_layer.set_weights([params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"], params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]])\n",
    "            perceptron_layer.set_weights([params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"], params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]])\n",
    "            mlp_proj_layer.set_weights([params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"], params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]])\n",
    "            \n",
    "            block = tf.keras.Sequential([\n",
    "                norm1,\n",
    "                query_layer,\n",
    "                key_layer,\n",
    "                value_layer,\n",
    "                proj_layer,\n",
    "                norm2,\n",
    "                perceptron_layer,\n",
    "                mlp_proj_layer\n",
    "                ],\n",
    "                name=f\"block-{b}\")\n",
    "            self.blocks.append(block)\n",
    "        final_norm_beta = tf.keras.initializers.Constant(params[\"b\"])\n",
    "        final_norm_gamma = tf.keras.initializers.Constant(params[\"g\"])\n",
    "        self.final_norm = tf.keras.layers.LayerNormalization(beta_initializer=final_norm_beta, gamma_initializer=final_norm_gamma, name=f\"final-norm\")\n",
    "        self.out_head_layer = tf.keras.layers.Dense(units=50257, activation=None, use_bias=False, name=f\"out-head\")\n",
    "        self.out_head_layer.build((50257, 768))\n",
    "        self.out_head_layer.set_weights([params['wte'].T])\n",
    "    def __call__(self, inputs):\n",
    "        print(\"inputs.shape:\", inputs.shape)\n",
    "        we = word_emb(inputs)\n",
    "        print(\"we.shape:\", we.shape)\n",
    "        pe = pos_emb(tf.range(1024))\n",
    "        print(\"pe.shape:\", pe.shape)\n",
    "        pe_corrected = pe[:we.shape[1], :]\n",
    "        print(\"pe_corrected.shape:\", pe_corrected.shape)\n",
    "        x = we + pe_corrected\n",
    "        print(\"1 x.shape:\", x.shape)\n",
    "        print(\"1 x:\", x[0][0][:3].numpy())\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            print(\"  b x.shape:\", x.shape)\n",
    "            print(\"  b x:\", x[0][0][:3].numpy())\n",
    "        print(\"2 x.shape:\", x.shape)\n",
    "        print(\"2 x:\", x[0][0][:3].numpy())\n",
    "        x = self.final_norm(x)\n",
    "        print(\"3 x.shape:\", x.shape)\n",
    "        print(\"3 x:\", x[0][0][:3].numpy())\n",
    "        x = self.out_head_layer(x)\n",
    "        print(\"4 x.shape:\", x.shape)\n",
    "        print(\"4 x:\", x[0][0][:3].numpy())\n",
    "        return x\n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2646c09d-f97c-41c2-9e5d-5002a57ec939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config124M = {'n_embd': 768, 'n_vocab': 50257, 'n_ctx': 1024, 'n_layer': 12, 'n_head': 12}\n",
    "model=GPT21(config124M)\n",
    "\n",
    "x_trivial = tf.constant([[1, 2, 3]])\n",
    "#e = model(x_trivial) # [-32.901043, -31.202375, -34.662212\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c43be28b-9544-4d2b-94d3-b0187ed4e63e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 768), dtype=float32, numpy=\n",
       "array([[[ 0.02151961, -0.24603364,  0.05027542, ...,  0.04301079,\n",
       "          0.03080702,  0.09767969],\n",
       "        [-0.10350236, -0.00585408,  0.0892228 , ...,  0.12408535,\n",
       "         -0.11955193, -0.08801492],\n",
       "        [-0.08849797, -0.39009592,  0.26571876, ...,  0.19665493,\n",
       "          0.055693  , -0.2011495 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb = model.word_emb\n",
    "pos_emb = model.pos_emb\n",
    "x = word_emb(x_trivial)\n",
    "pe = pos_emb(tf.range(1024))\n",
    "pe_corrected = pe[:we.shape[1], :]\n",
    "x_embedded = we + pe_corrected\n",
    "x_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64ea5358-b4ad-424a-97ed-f7516a5d4b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x01: [ 0.00979763 -0.09247549 -0.04293772]\n"
     ]
    }
   ],
   "source": [
    "block0 = model.get_layer('block-0')\n",
    "norm10 = block0.get_layer('norm1-0')\n",
    "x01 = norm10(x_embedded)\n",
    "print('x01:', x01[0][0][:3].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5621443a-e5c6-4a6f-9abe-ed8d28f3acda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query0 = block0.get_layer('query-0')\n",
    "key0 = block0.get_layer('key-0')\n",
    "value0 = block0.get_layer('value-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "698ae30a-3c2a-4ced-aa31-2d13ad6aac0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x02: [-9.707672 14.597338 -9.301317]\n"
     ]
    }
   ],
   "source": [
    "x02 = value0(key0(query0(x01)))\n",
    "print('x02:', x02[0][0][:3].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4fbd2b-4ca9-4a75-b51c-c91fdc9ee619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
