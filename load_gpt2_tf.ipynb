{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5627e4-de33-4b92-be9d-916b59b379f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensorflow gpt2 implemenation\n",
    "\n",
    "Here we define a tensorflow implementation of gpt2 as provided by https://github.com/ShenakhtPajouh/gpt2-keras\n",
    "and load the weights. The goal is to duplicate as closely as possible the Pytorch implemenation\n",
    "from LLMFS. See load_gpt.ipynb in ch05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f793526-3c5f-4f4a-a010-bf639c158852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "!pip install -q tiktoken\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda5a7c-f36e-4384-9f61-adcec16958ef",
   "metadata": {},
   "source": [
    "## gpt2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a395063b-f082-483f-bcc9-fa7919d0288a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://github.com/ShenakhtPajouh/gpt2-keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_tensor_shape(x):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    static_shape = x.shape.as_list()\n",
    "    if tf.executing_eagerly():\n",
    "        return static_shape\n",
    "    dynamic_shape = tf.shape(x)\n",
    "    if static_shape is None:\n",
    "        return dynamic_shape\n",
    "    dynamic_shape = tf.unstack(dynamic_shape)\n",
    "    shape = []\n",
    "    for st, dyn in zip(static_shape, dynamic_shape):\n",
    "        if st is None:\n",
    "            shape.append(dyn)\n",
    "        else:\n",
    "            shape.append(st)\n",
    "    return shape\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "def dropout_fn(x, dropout):\n",
    "    if dropout is None or dropout == 0.0:\n",
    "        return x\n",
    "    else:\n",
    "        return tf.nn.dropout(x, rate=dropout)\n",
    "\n",
    "\n",
    "class LayerNormalization(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, trainable=True, name=None):\n",
    "        super().__init__(name=name, trainable=trainable)\n",
    "        self.beta = None\n",
    "        self.gamma = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.beta = self.add_weight(name=\"beta\", shape=input_shape[-1:], initializer=tf.zeros_initializer())\n",
    "        self.gamma = self.add_weight(name=\"gamma\", shape=input_shape[-1:], initializer=tf.ones_initializer())\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, axis=-1, epsilon=1e-5):\n",
    "        # mean, variance = tf.nn.moments(inputs, axis, keep_dims=True)\n",
    "        mean, variance = tf.nn.moments(inputs, axis, keepdims=True)\n",
    "        rdev = tf.math.rsqrt(variance + epsilon)\n",
    "        x = (inputs - mean) * rdev\n",
    "        output = x * self.gamma + self.beta\n",
    "        return output\n",
    "\n",
    "    def __call__(self, inputs, axis=-1, epsilon=1e-5):\n",
    "        return super().__call__(inputs=inputs,\n",
    "                                axis=axis, epsilon=epsilon)\n",
    "\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_attention_heads=1, size_per_head=512,\n",
    "                 one_sided=True,\n",
    "                 query_act=None,\n",
    "                 initializer_range=0.02,\n",
    "                 value_act=None,\n",
    "                 key_act=None,\n",
    "                 trainable=True,\n",
    "                 name=None):\n",
    "        super().__init__(name=name, trainable=trainable)\n",
    "        # `query_layer` = [B*F, N*H]\n",
    "        self.attention_size = num_attention_heads * size_per_head\n",
    "        self.query_layer = tf.keras.layers.Dense(\n",
    "            num_attention_heads * size_per_head,\n",
    "            activation=query_act,\n",
    "            name=\"query\",\n",
    "            kernel_initializer=tf.random_normal_initializer(stddev=initializer_range)\n",
    "        )\n",
    "        # `key_layer` = [B*T, N*H]\n",
    "        self.key_layer = tf.keras.layers.Dense(\n",
    "            num_attention_heads * size_per_head,\n",
    "            activation=key_act,\n",
    "            name=\"key\",\n",
    "            kernel_initializer=tf.random_normal_initializer(stddev=initializer_range)\n",
    "        )\n",
    "        # `value_layer` = [B*T, N*H]\n",
    "        self.value_layer = tf.keras.layers.Dense(\n",
    "            num_attention_heads * size_per_head,\n",
    "            activation=value_act,\n",
    "            name=\"value\",\n",
    "            kernel_initializer=tf.random_normal_initializer(stddev=initializer_range)\n",
    "        )\n",
    "        self.size_per_head = size_per_head\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.one_sided = one_sided\n",
    "\n",
    "    def reshape(self, x, use_2d=False, shape=None):\n",
    "        if use_2d:\n",
    "            batch_size, seq_length = shape[0], shape[1]\n",
    "        else:\n",
    "            _shape = get_tensor_shape(x)\n",
    "            batch_size, seq_length = _shape[0], _shape[1]\n",
    "        x = tf.reshape(x, [batch_size, seq_length, self.num_attention_heads, self.size_per_head])\n",
    "        x = tf.transpose(x, [0, 2, 1, 3])\n",
    "        return x\n",
    "\n",
    "    def final_shape(self, x, use_2d=False):\n",
    "        shape = get_tensor_shape(x)\n",
    "        batch_size, seq_length = shape[0], shape[2]\n",
    "        x = tf.transpose(x, [0, 2, 1, 3])\n",
    "        if use_2d:\n",
    "            x = tf.reshape(x, [batch_size * seq_length, self.num_attention_heads * self.size_per_head])\n",
    "        else:\n",
    "            x = tf.reshape(x, [batch_size, seq_length, self.num_attention_heads * self.size_per_head])\n",
    "        return x\n",
    "\n",
    "    def get_mask(self, inputs_shape, cache_length=None, mask=None):\n",
    "        batch_size, seq_length = inputs_shape[0], inputs_shape[2]\n",
    "        if self.one_sided:\n",
    "            rng = tf.range(seq_length)\n",
    "            one_sided_mask = tf.less_equal(rng, tf.expand_dims(rng, 1))\n",
    "            if cache_length is not None:\n",
    "                prev_mask = tf.ones([seq_length, cache_length], tf.bool)\n",
    "                one_sided_mask = tf.concat([prev_mask, one_sided_mask], 1)\n",
    "        if mask is not None:\n",
    "            if cache_length is not None:\n",
    "                prev_mask = tf.ones([batch_size, cache_length], tf.bool)\n",
    "                mask = tf.concat([prev_mask, mask], 1)\n",
    "            if cache_length is None:\n",
    "                cache_length = 0\n",
    "            mask = tf.reshape(mask, [batch_size, 1, 1, seq_length + cache_length])\n",
    "        if self.one_sided:\n",
    "            if mask is not None:\n",
    "                one_sided_mask = tf.logical_and(mask, one_sided_mask)\n",
    "            return one_sided_mask\n",
    "        else:\n",
    "            return mask\n",
    "\n",
    "    def attend(self, query, key, value, mask=None, dropout=None):\n",
    "        dim = tf.cast(self.size_per_head, query.dtype)\n",
    "        _sqrt = tf.math.sqrt(dim)\n",
    "        _sqrt = tf.cast(_sqrt, query.dtype)\n",
    "        coefficients = tf.matmul(query, key, transpose_b=True) / _sqrt\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, coefficients.dtype)\n",
    "            coefficients = coefficients * mask - (1 - mask) * 1e5\n",
    "        coefficients = tf.math.softmax(coefficients, -1)\n",
    "        coefficients = dropout_fn(coefficients, dropout)\n",
    "        results = tf.matmul(coefficients, value)\n",
    "        return results\n",
    "\n",
    "    def call(self, inputs, cache=None, mask=None,\n",
    "             attention_dropout=None, return_cache=False,\n",
    "             use_2d=False, shape=None):\n",
    "        \"\"\"\n",
    "        inputs: a tensor of shape [batch_size, seq_length, dim] if use_2d is false,\n",
    "                else a tensor of shape [batch_size * seq_length, dim]\n",
    "        cache: A dictionary consist of key and value from previous calls.\n",
    "        mask: a boolean tensor of shape [batch_size, seq_length]\n",
    "        attention_probs_dropout_prob: dropout use for attention mechanism\n",
    "        return_cache: if True, it returns key and values as besides layer output\n",
    "        use_2d: if it is True, the model uses 2D matrices as inputs and outputs\n",
    "        shape: if use_2d is True, then the shape is [batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        query = self.query_layer(inputs)\n",
    "        key = self.key_layer(inputs)\n",
    "        value = self.value_layer(inputs)\n",
    "        if use_2d and shape is None:\n",
    "            raise ValueError(\"if use_2d is True, then the shape must be specified\")\n",
    "        query = self.reshape(query, use_2d, shape)\n",
    "        key = self.reshape(key, use_2d, shape)\n",
    "        value = self.reshape(value, use_2d, shape)\n",
    "        cache_length = None\n",
    "        if cache is not None:\n",
    "            key = tf.concat([cache[\"key\"], key], 2)\n",
    "            value = tf.concat([cache[\"value\"], value], 2)\n",
    "            cache_length = get_tensor_shape(cache[\"key\"])[2]\n",
    "        inputs_shape = get_tensor_shape(query)\n",
    "        mask = self.get_mask(inputs_shape, cache_length, mask)\n",
    "        result = self.attend(query, key, value, mask, attention_dropout)\n",
    "        result = self.final_shape(result, use_2d)\n",
    "        if return_cache:\n",
    "            cache = {\"key\": key, \"value\": value}\n",
    "            return result, cache\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def __call__(self, inputs, cache=None, mask=None,\n",
    "             attention_dropout=None, return_cache=False,\n",
    "             use_2d=False, shape=None):\n",
    "        \"\"\"\n",
    "        inputs: a tensor of shape [batch_size, seq_length, dim] if use_2d is false,\n",
    "                else a tensor of shape [batch_size * seq_length, dim]\n",
    "        cache: A dictionary consist of key and value from previous calls.\n",
    "        mask: a boolean tensor of shape [batch_size, seq_length]\n",
    "        attention_probs_dropout_prob: dropout use for attention mechanism\n",
    "        return_cache: if True, it returns key and values as besides layer output\n",
    "        use_2d: if it is True, the model uses 2D matrices as inputs and outputs\n",
    "        shape: if use_2d is True, then the shape is [batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        return super().__call__(\n",
    "            inputs=inputs,\n",
    "            cache=cache,\n",
    "            mask=mask,\n",
    "            attention_dropout=attention_dropout,\n",
    "            return_cache=return_cache,\n",
    "            use_2d=use_2d,\n",
    "            shape=shape\n",
    "        )\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, config, name=None, trainable=True, initializer_range=0.02):\n",
    "        super().__init__(name=name, trainable=trainable)\n",
    "        self.layer_norm = LayerNormalization(name=\"layer_norm\")\n",
    "        self.self_attention = SelfAttention(num_attention_heads=config[\"n_head\"],\n",
    "                                            size_per_head=config[\"n_embd\"] // config[\"n_head\"],\n",
    "                                            initializer_range=initializer_range,\n",
    "                                            name=\"self\"\n",
    "                                            )\n",
    "        self.projection = tf.keras.layers.Dense(units=config[\"n_embd\"],\n",
    "                                                kernel_initializer=tf.random_normal_initializer(stddev=initializer_range),\n",
    "                                                name=\"projection\")\n",
    "\n",
    "\n",
    "    def call(self, inputs, cache=None, dropout=None, attention_dropout=None,\n",
    "             return_cache=False, use_2d=False, shape=None):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: a tensor of shape [batch_size, seq_length, dim] if use_2d is False, else [batch_size * seq_length, dim]\n",
    "        cache: (Optional): a dictionary of tensors key and value from previous calls.\n",
    "        return_cache: if True, returns a dictionary of key and value tensors besides layer output.\n",
    "        use_2d: if is True then the inputs and outputs are 2D tensors instead of 3D (for tpu performance)\n",
    "        shape: if use_2d then it's [batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        x = self.layer_norm(inputs)\n",
    "        x = self.self_attention(x, attention_dropout=attention_dropout,\n",
    "                                cache=cache,\n",
    "                                return_cache=return_cache,\n",
    "                                use_2d=use_2d,\n",
    "                                shape=shape)\n",
    "        if return_cache:\n",
    "            x, cache = x\n",
    "        x = self.projection(x)\n",
    "        x = dropout_fn(x, dropout)\n",
    "        if return_cache:\n",
    "            return x, cache\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __call__(self, inputs, cache=None, dropout=None, attention_dropout=None,\n",
    "                 return_cache=False, use_2d=False, shape=None):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: a tensor of shape [batch_size, seq_length, dim] if use_2d is False, else [batch_size * seq_length, dim]\n",
    "        cache: (Optional): a dictionary of tensors key and value from previous calls.\n",
    "        return_cache: if True, returns a dictionary of key and value tensors besides layer output.\n",
    "        use_2d: if is True then the inputs and outputs are 2D tensors instead of 3D (for tpu performance)\n",
    "        shape: if use_2d then it's [batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        return super().__call__(\n",
    "            inputs=inputs,\n",
    "            cache=cache,\n",
    "            dropout=dropout,\n",
    "            attention_dropout=attention_dropout,\n",
    "            return_cache=return_cache,\n",
    "            use_2d=use_2d,\n",
    "            shape=shape\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, activation_fn=None, embedding_size=768,\n",
    "                 perceptron_size=3072, trainable=True,\n",
    "                 initializer_range=0.02, name=None):\n",
    "        super().__init__(name=name, trainable=trainable)\n",
    "        self.layer_norm = LayerNormalization(name=\"layer_norm\")\n",
    "        self.perceptron = tf.keras.layers.Dense(units=perceptron_size,\n",
    "                                                activation=activation_fn,\n",
    "                                                kernel_initializer=tf.random_normal_initializer(stddev=initializer_range),\n",
    "                                                name=\"perceptron\")\n",
    "        self.projection = tf.keras.layers.Dense(units=embedding_size,\n",
    "                                                kernel_initializer=tf.random_normal_initializer(stddev=initializer_range),\n",
    "                                                name=\"projection\")\n",
    "\n",
    "    def call(self, inputs, dropout=None):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: tensor of [batch_size, seq_length, dim]\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.layer_norm(inputs)\n",
    "        x = self.perceptron(x)\n",
    "        x = self.projection(x)\n",
    "        x = dropout_fn(x, dropout)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs, dropout=None):\n",
    "        return super().__call__(inputs=inputs,\n",
    "                                dropout=dropout)\n",
    "\n",
    "\n",
    "class Block(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, config, trainable=True, initializer_range=0.02, name=None):\n",
    "        super().__init__(name=name, trainable=trainable)\n",
    "        self.attention = AttentionLayer(config=config,\n",
    "                                        initializer_range=initializer_range,\n",
    "                                        name=\"attention\")\n",
    "        self.mlp = MultiLayerPerceptron(activation_fn=gelu,\n",
    "                                        embedding_size=config[\"n_embd\"],\n",
    "                                        perceptron_size=4 * config[\"n_embd\"],\n",
    "                                        initializer_range=initializer_range,\n",
    "                                        name=\"mlp\")\n",
    "\n",
    "    def call(self, inputs, cache=None, dropout=None, attention_dropout=None,\n",
    "            return_cache=False, use_2d=False, shape=None):\n",
    "        x = inputs\n",
    "        a = self.attention(inputs=x,\n",
    "                           cache=cache,\n",
    "                           dropout=dropout,\n",
    "                           attention_dropout=attention_dropout,\n",
    "                           return_cache=return_cache,\n",
    "                           use_2d=use_2d,\n",
    "                           shape=shape)\n",
    "        if return_cache:\n",
    "            a, cache = a\n",
    "        x = x + a\n",
    "        m = self.mlp(inputs=x,\n",
    "                     dropout=dropout)\n",
    "        x = x + m\n",
    "        if return_cache:\n",
    "            return x, cache\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __call__(self, inputs, cache=None, dropout=None, attention_dropout=None,\n",
    "                 return_cache=False, use_2d=False, shape=None):\n",
    "        return super().__call__(inputs=inputs,\n",
    "                                cache=cache,\n",
    "                                dropout=dropout,\n",
    "                                attention_dropout=attention_dropout,\n",
    "                                return_cache=return_cache,\n",
    "                                use_2d=use_2d,\n",
    "                                shape=shape)\n",
    "\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, config, trainable=True, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.trainable = trainable\n",
    "        self.blocks = []\n",
    "        self.blocks_num = config[\"n_layer\"]\n",
    "        for ids in range(self.blocks_num):\n",
    "            block = Block(config=config,\n",
    "                          name=\"block_%d\" % ids)\n",
    "            self.blocks.append(block)\n",
    "        self.layer_norm = LayerNormalization(name=\"layer_norm\")\n",
    "\n",
    "    def call(self, inputs, cache=None, dropout=None, attention_dropout=None,\n",
    "             return_cache=False, blocks=None, use_2d=False, shape=None):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: a tensor of shape [batch_size, seq_length, dim], if use_2d is False, else [batch_size * seq_length, dim]\n",
    "        cache: a list of dictionaries. key and values from previous calls.\n",
    "        blocks: a list. if it is specified, the output will be a dictionary {layer_num: layer_output}\n",
    "        return_cache: if it is true, it will returns cache for blocks\n",
    "        use_2d: if it is True, then the operations will define base on 2D tensors. (for tpu performance)\n",
    "        shape: if use_2d is True, then it is [batch_size, seq_length]\n",
    "\n",
    "        \"\"\"\n",
    "        if blocks is None:\n",
    "            max_block = self.blocks_num - 1\n",
    "        elif len(blocks) == 0:\n",
    "            max_block = self.blocks_num - 1\n",
    "            blocks = None\n",
    "        else:\n",
    "            _blocks = []\n",
    "            for i in blocks:\n",
    "                if i >= 0:\n",
    "                    k = i\n",
    "                else:\n",
    "                    k = self.blocks_num - i\n",
    "                if k >= self.blocks_num or k < 0:\n",
    "                    raise ValueError(\"output blocks should be in range [\" + str(0) + \", \" +\n",
    "                                     str(self.blocks_num - 1) + \"]\")\n",
    "                _blocks.append(k)\n",
    "            _blocks = list(sorted(_blocks))\n",
    "            blocks = _blocks\n",
    "            max_block = blocks[-1]\n",
    "        if blocks is not None:\n",
    "            outputs = {}\n",
    "        if return_cache:\n",
    "            new_cache = []\n",
    "        output = inputs\n",
    "        for ids in range(max_block + 1):\n",
    "            if cache is None:\n",
    "                _cache = None\n",
    "            else:\n",
    "                _cache = cache[ids]\n",
    "            output = self.blocks[ids](inputs=output,\n",
    "                                      cache=_cache,\n",
    "                                      dropout=dropout,\n",
    "                                      attention_dropout=attention_dropout,\n",
    "                                      return_cache=return_cache,\n",
    "                                      use_2d=use_2d,\n",
    "                                      shape=shape)\n",
    "            if return_cache:\n",
    "                output, _cache = output\n",
    "                new_cache.append(_cache)\n",
    "            if blocks is not None:\n",
    "                if ids in blocks:\n",
    "                    outputs[ids] = output\n",
    "        if blocks is None:\n",
    "            output = self.layer_norm(output)\n",
    "            result = output\n",
    "        else:\n",
    "            result = outputs\n",
    "        if return_cache:\n",
    "            return result, new_cache\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def __call__(self, inputs, cache=None, dropout=None, attention_dropout=None,\n",
    "                 return_cache=False, blocks=None, use_2d=False, shape=None):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: a tensor of shape [batch_size, seq_length, dim], if use_2d is False, else [batch_size * seq_length, dim]\n",
    "        cache: a list of dictionaries. key and values from previous calls.\n",
    "        blocks: a list. if it is specified, the output will be a dictionary {layer_num: layer_output}\n",
    "        return_cache: if it is true, it will returns cache for blocks\n",
    "        use_2d: if it is True, then the operations will define base on 2D tensors. (for tpu performance)\n",
    "        shape: if use_2d is True, then it is [batch_size, seq_length]\n",
    "\n",
    "        \"\"\"\n",
    "        return super().__call__(\n",
    "            inputs=inputs,\n",
    "            cache=cache,\n",
    "            dropout=dropout,\n",
    "            attention_dropout=attention_dropout,\n",
    "            return_cache=return_cache,\n",
    "            blocks=blocks,\n",
    "            use_2d=use_2d,\n",
    "            shape=shape\n",
    "        )\n",
    "\n",
    "\n",
    "class Embedding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, embedding_size, vocab_size, max_position_length,\n",
    "                 trainable=True, name=None, initializer_range=0.02,\n",
    "                 dtype=None):\n",
    "        if dtype is None:\n",
    "            dtype = tf.float32\n",
    "        super().__init__(name=name, trainable=trainable, dtype=dtype)\n",
    "        self.word_embedding = None\n",
    "        self.position_embedding = None\n",
    "        self.initializer_range = initializer_range\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_position_length = max_position_length\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.word_embedding = self.add_weight(\n",
    "            name=\"word_embedding\",\n",
    "            shape=(self.vocab_size, self.embedding_size),\n",
    "            initializer=tf.random_normal_initializer(stddev=self.initializer_range),\n",
    "        )\n",
    "        self.position_embedding = self.add_weight(\n",
    "            name=\"position_embedding\",\n",
    "            shape=(self.max_position_length, self.embedding_size),\n",
    "            initializer=tf.random_normal_initializer(stddev=self.initializer_range),\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, start=None):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: integer tensor of [batch_size, seq_length]\n",
    "        start: start of positional embedding\n",
    "\n",
    "        \"\"\"\n",
    "        shape = get_tensor_shape(inputs)\n",
    "        x = tf.gather(self.word_embedding, inputs)\n",
    "        if start is None:\n",
    "            start = 0\n",
    "        end = start + shape[1]\n",
    "        pe = self.position_embedding[start:end]\n",
    "        x = x + pe\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs, start=None):\n",
    "        \"\"\"\n",
    "\n",
    "        if use_one_hot_keys is True, then inputs are one_hot tensors of shape [batch_size, seq_length, vocab_size],\n",
    "        else it is an integer tensor of [batch_size, seq_length] of token ids.\n",
    "        start: start of positional embedding\n",
    "\n",
    "        \"\"\"\n",
    "        return super().__call__(inputs=inputs, start=start)\n",
    "\n",
    "\n",
    "class GPT2(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, config, name=None, trainable=True, dtype=None):\n",
    "        super().__init__(name=name)\n",
    "        self.trainable = trainable\n",
    "        self.embedding = Embedding(\n",
    "            embedding_size=config['n_embd'],\n",
    "            vocab_size=config['n_vocab'],\n",
    "            max_position_length=config['n_ctx'],\n",
    "            name=\"embedding\",\n",
    "            dtype=dtype\n",
    "        )\n",
    "        self.transformer = Transformer(config, name=\"transformer\")\n",
    "\n",
    "    def call(self, inputs, cache=None,\n",
    "             dropout=None, attention_dropout=None,\n",
    "             return_cache=False, return_logits=True, use_2d=False):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: an integer tensor of shape [batch_size, seq_length] if not use_2d is False\n",
    "                else a one_hot tensor of shape [batch_size, seq_length, vocab_size]\n",
    "        cache: a list of dictionaries {\"key\": key, \"value\": value} of previous keys and values. it uses for generation\n",
    "        use_one_hot_keys: if True it uses one hot tensors for embedding layer.\n",
    "        return_cache: if True returns new keys and values alongside output. it uses for generation.\n",
    "        return_logits: if True, return logits, else return last layer embedding.\n",
    "        use_2d: for tpu performances: use 2D tensors for operations and return the output in 2D shape: [batch_size * seq_length, -1]\n",
    "\n",
    "        \"\"\"\n",
    "        if cache is not None:\n",
    "            _cache = cache[0][\"key\"]\n",
    "            start = get_tensor_shape(_cache)[2]\n",
    "        else:\n",
    "            start = None\n",
    "        x = self.embedding(inputs, start)\n",
    "        print(\"1 x:\", x[0][0][:3].numpy())\n",
    "        if use_2d:\n",
    "            shape = get_tensor_shape(x)\n",
    "            x = tf.reshape(x, [shape[0] * shape[1], shape[2]])\n",
    "            shape = shape[0:2]\n",
    "        else:\n",
    "            shape = None\n",
    "        x = self.transformer(\n",
    "            inputs=x,\n",
    "            cache=cache,\n",
    "            dropout=dropout,\n",
    "            attention_dropout=attention_dropout,\n",
    "            return_cache=return_cache,\n",
    "            use_2d=use_2d,\n",
    "            shape=shape\n",
    "        )\n",
    "        print(\"2 x:\", x[0][0][:3].numpy())\n",
    "        if return_cache:\n",
    "            x, cache = x\n",
    "        if return_logits:\n",
    "            shape = get_tensor_shape(x)\n",
    "            if not use_2d:\n",
    "                x = tf.reshape(x, [shape[0] * shape[1], shape[2]])\n",
    "            logits = tf.matmul(x, self.embedding.word_embedding, transpose_b=True)\n",
    "            if not use_2d:\n",
    "                logits = tf.reshape(logits, [shape[0], shape[1], self.embedding.vocab_size])\n",
    "            result = logits\n",
    "        else:\n",
    "            result = x\n",
    "        if return_cache:\n",
    "            return result, cache\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def __call__(self, inputs, cache=None,\n",
    "                 dropout=None, attention_dropout=None,\n",
    "                 return_cache=False, return_logits=True,\n",
    "                 use_2d=False):\n",
    "        \"\"\"\n",
    "\n",
    "        inputs: an integer tensor of shape [batch_size, seq_length]\n",
    "        cache: a list of dictionaries {\"key\": key, \"value\": value} of previous keys and values. it uses for generation\n",
    "        use_one_hot_keys: if True it uses one hot tensors for embedding layer.\n",
    "        return_cache: if True returns new keys and values alongside output. it uses for generation.\n",
    "        return_logits: if True, return logits, else return last layer embedding.\n",
    "        use_2d: for tpu performances: use 2D tensors for operations and return the output in 2D shape: [batch_size * seq_length, -1]\n",
    "\n",
    "        \"\"\"\n",
    "        return super().__call__(\n",
    "            inputs=inputs,\n",
    "            cache=cache,\n",
    "            dropout=dropout,\n",
    "            attention_dropout=attention_dropout,\n",
    "            return_cache=return_cache,\n",
    "            return_logits=return_logits,\n",
    "            use_2d=use_2d\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98f72660-ef8e-4002-82aa-a54b2874e5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config124M = {'n_embd': 768, 'n_vocab': 50257, 'n_ctx': 1024, 'n_layer': 12, 'n_head': 12}\n",
    "# config = {'n_embd': 3, 'n_vocab': 10, 'n_ctx': 5, 'n_layer': 12, 'n_head': 4}\n",
    "gpt2 = GPT2(name=\"mygpt2\", config=config124M)\n",
    "x=tf.constant([[1]])\n",
    "gpt2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0cd9eed-3d04-4b10-9482-9f386a54fc67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 x: [-0.00598396  0.02429412 -0.004852  ]\n",
      "2 x: [ 0.49031234  0.04267193 -0.9410458 ]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'mygpt2' (type GPT2).\n\n{{function_node __wrapped__ReadVariableOp_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50257,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc name: \n\nCall arguments received by layer 'mygpt2' (type GPT2):\n  • inputs=tf.Tensor(shape=(1, 1), dtype=int32)\n  • cache=None\n  • dropout=None\n  • attention_dropout=None\n  • return_cache=False\n  • return_logits=True\n  • use_2d=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 586\u001b[0m, in \u001b[0;36mGPT2.__call__\u001b[0;34m(self, inputs, cache, dropout, attention_dropout, return_cache, return_logits, use_2d)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m              dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m              return_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    575\u001b[0m              use_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    576\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    inputs: an integer tensor of shape [batch_size, seq_length]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m \n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_2d\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[28], line 561\u001b[0m, in \u001b[0;36mGPT2.call\u001b[0;34m(self, inputs, cache, dropout, attention_dropout, return_cache, return_logits, use_2d)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_2d:\n\u001b[1;32m    560\u001b[0m     x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(x, [shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m shape[\u001b[38;5;241m1\u001b[39m], shape[\u001b[38;5;241m2\u001b[39m]])\n\u001b[0;32m--> 561\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_2d:\n\u001b[1;32m    563\u001b[0m     logits \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(logits, [shape[\u001b[38;5;241m0\u001b[39m], shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mvocab_size])\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'mygpt2' (type GPT2).\n\n{{function_node __wrapped__ReadVariableOp_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50257,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc name: \n\nCall arguments received by layer 'mygpt2' (type GPT2):\n  • inputs=tf.Tensor(shape=(1, 1), dtype=int32)\n  • cache=None\n  • dropout=None\n  • attention_dropout=None\n  • return_cache=False\n  • return_logits=True\n  • use_2d=False"
     ]
    }
   ],
   "source": [
    "gpt2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b889a6-3dd2-48a8-bd4a-106c5bb1dd58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mygpt2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  39383808  \n",
      "                                                                 \n",
      " transformer (Transformer)   multiple                  85056000  \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| block_0 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_1 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_2 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_3 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_4 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_5 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_6 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_7 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_8 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_9 (Block)            multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_10 (Block)           multiple                  7087872  |\n",
      "|                                                               |\n",
      "| block_11 (Block)           multiple                  7087872  |\n",
      "|                                                               |\n",
      "| layer_norm (LayerNormaliz  multiple                  1536     |\n",
      "| ation)                                                        |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 124439808 (474.70 MB)\n",
      "Trainable params: 124439808 (474.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2.summary(expand_nested=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5fccc7-e7ff-4cbe-b5ba-2f62cb0c8903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Manual Recursive Traversal ---\n",
      "- mygpt2 (GPT2)\n",
      "  - embedding (Embedding)\n",
      "  - transformer (Transformer)\n",
      "    - block_0 (Block)\n",
      "    - block_1 (Block)\n",
      "    - block_2 (Block)\n",
      "    - block_3 (Block)\n",
      "    - block_4 (Block)\n",
      "    - block_5 (Block)\n",
      "    - block_6 (Block)\n",
      "    - block_7 (Block)\n",
      "    - block_8 (Block)\n",
      "    - block_9 (Block)\n",
      "    - block_10 (Block)\n",
      "    - block_11 (Block)\n",
      "    - layer_norm (LayerNormalization)\n"
     ]
    }
   ],
   "source": [
    "def print_layer_structure(layer_or_model, level=0):\n",
    "    \"\"\"Recursively prints the structure of a Keras layer or Model.\"\"\"\n",
    "    indent = \"  \" * level\n",
    "    # Print the current layer's name and class\n",
    "    print(f\"{indent}- {layer_or_model.name} ({type(layer_or_model).__name__})\")\n",
    "\n",
    "    # The .layers property lists layers that are children of the current one\n",
    "    if hasattr(layer_or_model, 'layers') and layer_or_model.layers:\n",
    "        for inner_layer in layer_or_model.layers:\n",
    "            # Recursively call the function for nested components\n",
    "            print_layer_structure(inner_layer, level + 1)\n",
    "            \n",
    "# Use the same 'model' object from the previous example\n",
    "print(\"\\n--- Manual Recursive Traversal ---\")\n",
    "print_layer_structure(gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33fbdc7b-271d-4e09-b108-07c69fffa529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(gpt2)\n",
    "model_dir = 'tf_ckpts'\n",
    "save_path = checkpoint.save(model_dir + \"/ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781d3649-e8fe-42fe-8fbb-974e88a1ac17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all the variables in the model\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "for name, v in tf.train.list_variables(tf_ckpt_path):\n",
    "    # print(name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24678145-3d29-40a8-b11e-5a4b8c29c37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load weights into a \"params\" dict\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7cb6561-3175-4f95-bf0b-34ecbf8258de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "settings = {\"n_layer\": 12}\n",
    "\n",
    "model_dir=\"ch05/01_main-chapter-code/gpt2/124M\"\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6d42da0-3ab4-4142-8cda-d46c4a9bdd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's study this \"params\" thing..\n",
    "params.keys() # ['blocks', 'b', 'g', 'wpe', 'wte']\n",
    "len(params[\"blocks\"]) # 12\n",
    "params_block0 = params[\"blocks\"][0]\n",
    "params_block0.keys() # ['attn', 'ln_1', 'ln_2', 'mlp']\n",
    "params_block0_attn = params_block0['attn']\n",
    "params_block0_attn.keys() # ['c_attn', 'c_proj']\n",
    "params_block0_attn_c_attn = params_block0_attn['c_attn']\n",
    "params_block0_attn_c_attn.keys() # ['b', 'w']\n",
    "x = (params[\"blocks\"][0][\"attn\"][\"c_attn\"])[\"w\"]\n",
    "x.shape # (768, 2304)\n",
    "q_w, k_w, v_w = np.split((params[\"blocks\"][0][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "q_w.shape # (768, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8babea10-7191-4e0d-a266-a93cc13db58d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 768)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params['wpe'].shape # (1024, 768) position embedding\n",
    "params['wte'].shape # (50257, 768) token embedding, out_head.weight\n",
    "#len(params['blocks']) 12\n",
    "#params['blocks'][0].keys() # dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])\n",
    "# params['b'].shape # (768,) final_norm.shift (beta)\n",
    "# params['g'].shape # (768,) final_norm.scale (gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47c611bc-bdfa-4cb6-a4a2-f602ae14b77d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mygpt2',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'config': {'n_embd': 768,\n",
       "  'n_vocab': 50257,\n",
       "  'n_ctx': 1024,\n",
       "  'n_layer': 12,\n",
       "  'n_head': 12}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7c642-a108-4e24-a6c1-187c75101c1f",
   "metadata": {},
   "source": [
    "## Here we load all the weights!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f99fbf07-14c6-4dab-9996-2feaf1cc81f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a GPT Model has an Embedding layer and a Transformer Model\n",
    "embedding_layer   = gpt2.embedding\n",
    "\n",
    "# The Embedding Layer has word_embedding, position_embedding, initializer_range, embedding_size, vocab_size, max_position_length\n",
    "embedding_layer.word_embedding     = params['wte'] # word_embedding: (50257, 768) self.vocab_size, self.embedding_size\n",
    "embedding_layer.position_embedding = params['wpe'] # position_embedding: (1024, 768) max_position_length, self.embedding_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7885541f-bde8-4f62-a3da-bfd5d08cc072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer_layer = gpt2.transformer\n",
    "blocks = []\n",
    "for b in range(gpt2.get_config()['config']['n_layer']): # = transformer_layer.blocks_num (12)\n",
    "  # A transformer_layer has a list of blocks\n",
    "  block = transformer_layer.blocks[b]\n",
    "  blocks.append(block)\n",
    "\n",
    "  # Each Block Layer has an AttentionLayer and a MultiLayerPerceptron Layer \n",
    "  attn = block.attention\n",
    "\n",
    "  # Each AttentionLayer has a LayerNormalization layer and a SelfAttentionLayer and a Dense (\"Projection\") layer\n",
    "  layer_norm = attn.layer_norm\n",
    "  layer_norm.beta = params[\"blocks\"][b][\"ln_1\"][\"b\"] # Not real sure about these..\n",
    "  layer_norm.gamma = params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "  self_attention = attn.self_attention\n",
    "\n",
    "  # Each SelfAttentionLayer has a query_layer, a key_layer and a value_layer\n",
    "  query_layer = self_attention.query_layer\n",
    "  key_layer = self_attention.key_layer\n",
    "  value_layer = self_attention.value_layer\n",
    "  q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "  q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "  query_layer.set_weights([q_w, q_b])\n",
    "  key_layer.set_weights([k_w, k_b])\n",
    "  value_layer.set_weights([v_w, v_b])\n",
    "\n",
    "  layer_proj = attn.projection\n",
    "  layer_proj.set_weights([params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"], params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]])\n",
    "\n",
    "  mlp_layer = block.mlp\n",
    "  # A MultiLayerPerceptron layer has a LayerNormalization layer and 2 Dense Layers\n",
    "  mlp_layer_norm = mlp_layer.layer_norm\n",
    "  mlp_layer_norm.beta = params[\"blocks\"][b][\"ln_2\"][\"b\"] # Not real sure about these..\n",
    "  mlp_layer_norm.gamma = params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "  mlp_perceptron = mlp_layer.perceptron\n",
    "  mlp_perceptron.set_weights([params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"], params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]])\n",
    "  mlp_projection = mlp_layer.projection\n",
    "  mlp_projection.set_weights([params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"], params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]])\n",
    "final_norm_layer = transformer_layer.layer_norm\n",
    "final_norm_layer.beta = params[\"b\"]\n",
    "final_norm_layer.gamma = params[\"g\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017971c5-c758-4ba8-bd22-a4556469d585",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test each layer, comparing to corresponding LLMFS Pytorch layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80ec62ac-9f2a-4547-ba93-efd786cdb7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test embedding_layer\n",
    "x_embedded = embedding_layer(tf.constant([[1]]))\n",
    "#x_embedded # [ 2.1520e-02, -2.4603e-01,  5.0275e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d834231f-dedc-4db8-a74c-ad89d127f57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test layer_norm\n",
    "x = np.ones((1, 768) , dtype=np.float32)\n",
    "\n",
    "layer_norm0 = blocks[0].attention.layer_norm\n",
    "# layer_norm0(x) # [-3.6773e-03,  2.7197e-02, -6.4041e-02\n",
    "# layer_norm11 = blocks[11].attention.layer_norm\n",
    "# layer_norm11(x) # [ 5.0957e-02,  5.3063e-03,  7.1952e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea26a991-cb06-4fe3-88d0-26ee118b6e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test query_layer, key_layer, value_layer, layer_proj\n",
    "x = tf.constant(np.ones((1, 768) , dtype=np.float32))\n",
    "# block 0\n",
    "query_layer0 = blocks[0].attention.self_attention.query_layer\n",
    "#query_layer0(x) # [-1.3708e+01,  1.3385e+01,  1.4323e+01\n",
    "key_layer0 = blocks[0].attention.self_attention.key_layer\n",
    "# key_layer0(x) [ 1.8049e-01, -1.4381e-01,  6.2964e-01\n",
    "value_layer0 = blocks[0].attention.self_attention.value_layer               \n",
    "# value_layer0(x) # [-6.1687e-02, -1.3786e-01, -3.0145e-01\n",
    "layer_proj0 = blocks[0].attention.projection\n",
    "# layer_proj0(x) # [-9.7561e+00, -1.7296e+01, -6.7800e-01\n",
    "# layer_proj0(value_layer0(key_layer0(query_layer0(x)))) # [-2.3273e+01, -7.9272e+02,  5.6245e+02\n",
    "\n",
    "# block 11\n",
    "query_layer11 = blocks[11].attention.self_attention.query_layer\n",
    "# query_layer11(x) # [-5.4209e+00,  4.6236e+00,  4.5401e+00\n",
    "key_layer11 = blocks[11].attention.self_attention.key_layer\n",
    "# key_layer11(x) # [ 5.8911e+00, -3.3184e-01,  6.3656e-01\n",
    "value_layer11 = blocks[11].attention.self_attention.value_layer               \n",
    "# value_layer11(x) # [-1.2480e+00, -3.0783e+00,  5.9679e+00\n",
    "layer_proj11 = blocks[11].attention.projection\n",
    "#layer_proj11(x) # [-4.1535e-01,  2.1763e+00,  4.7958e-01\n",
    "\n",
    "# layer_proj11(value_layer11(key_layer11(query_layer11(x)))) # [ 3.4414e+02,  4.9568e+02,  3.8639e+02\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "039502a2-b4ec-4b40-b269-21c7fb195d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test mlp_layer_norm, mlp_perceptron, mlp_projection\n",
    "x = np.ones((1, 768) , dtype=np.float32)\n",
    "mlp_layer_norm0 = blocks[0].mlp.layer_norm\n",
    "# mlp_layer_norm0(x) # [ 4.2478e-02,  3.2627e-02,  4.4881e-03\n",
    "\n",
    "mlp_perceptron0 = blocks[0].mlp.perceptron\n",
    "mlp_projection0 = blocks[0].mlp.projection\n",
    "# mlp_projection0(mlp_perceptron0(x)) # [-1.6735e+01, -6.9883e+00,  4.1138e+00\n",
    "\n",
    "mlp_layer_norm11 = blocks[11].mlp.layer_norm\n",
    "# mlp_layer_norm11(x) # [-1.9770e-03,  2.0055e-02,  3.8334e-02\n",
    "\n",
    "mlp_perceptron11 = blocks[11].mlp.perceptron\n",
    "mlp_projection11 = blocks[11].mlp.projection\n",
    "#mlp_projection11(mlp_perceptron11(x)) # [ 1.3675e+01,  2.2839e+01, -1.7306e+01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95267c35-3b8e-4ce3-a9bc-0384aa33e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 x: [ 0.02151961 -0.24603364  0.05027542]\n",
      "2 x: [-0.05177143  0.12072419 -0.42840737]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 50257), dtype=float32, numpy=\n",
       "array([[[-32.90102 , -31.202356, -34.662197, ..., -39.48669 ,\n",
       "         -39.873096, -32.23865 ],\n",
       "        [-55.520763, -53.42853 , -56.476704, ..., -68.153885,\n",
       "         -66.77085 , -58.60061 ],\n",
       "        [-61.79686 , -60.538612, -59.550335, ..., -75.32061 ,\n",
       "         -72.773125, -65.57064 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trivial = tf.constant([[1, 2, 3]])\n",
    "gpt2(x_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a4729d1-5cc8-4532-af94-777a358573b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 768), dtype=float32, numpy=\n",
       "array([[[ 0.02151961, -0.24603364,  0.05027542, ...,  0.04301079,\n",
       "          0.03080702,  0.09767969],\n",
       "        [-0.10350236, -0.00585408,  0.0892228 , ...,  0.12408535,\n",
       "         -0.11955193, -0.08801492],\n",
       "        [-0.08849797, -0.39009592,  0.26571876, ...,  0.19665493,\n",
       "          0.055693  , -0.2011495 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_emb = gpt2.word_emb\n",
    "# pos_emb = gpt2.pos_emb\n",
    "# we = word_emb(x_trivial) # .shape # TensorShape([1, 3, 768])\n",
    "# pe = pos_emb(tf.range(1024)) # .shape # TensorShape([1024, 768])\n",
    "# x = we + pe\n",
    "emb = gpt2.embedding\n",
    "emb(x_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46f31bd9-8a69-4dce-824a-b96a5c17d171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    idx = tf.cast(idx, dtype=tf.int64)\n",
    "    for i in range(max_new_tokens):\n",
    "        idx_cond = idx\n",
    "        # print(\"i=\", i, \"idx_cond=\", idx_cond)\n",
    "        logits = model(idx)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = tf.nn.softmax(logits, -1)\n",
    "        idx_next = tf.argmax(logits)\n",
    "        idx_next = tf.argmax(probas, -1)        \n",
    "        # print(\"idx_next:\", idx_next)\n",
    "        idx_next_expanded = tf.expand_dims(idx_next, axis=0)\n",
    "        # print(\"idx_next_expanded:\", idx_next_expanded)\n",
    "        idx = tf.concat((idx, idx_next_expanded), axis=1)\n",
    "        # print(\"idx_next_expanded after concat:\", idx_next_expanded)\n",
    "        # print(\"idx               after concat:\", idx)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43d2896f-e9d5-4bc8-b70d-d849ce274eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids: tf.Tensor([[6109 3626 6100  345 2651   13  198  198  464]], shape=(1, 9), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = tf.constant([[6109 , 3626, 6100,  345]])\n",
    "token_ids = generate_text_simple(gpt2, idx=idx, max_new_tokens=5, context_size=256)\n",
    "print(\"token_ids:\", token_ids) # [6109, 3626, 6100,  345, 2651,   13,  198,  198,  464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd5ef5b7-2092-4cdf-a24e-adb7535bb5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[6109 3626 6100  345]], shape=(1, 4), dtype=int32)\n",
      "logits:\n",
      " tf.Tensor(\n",
      "[[[ -35.582027  -34.980392  -38.452198 ...  -42.095932  -41.85325\n",
      "    -35.596558]\n",
      "  [ -76.96017   -76.697     -81.9309   ...  -88.79839   -86.763176\n",
      "    -78.96271 ]\n",
      "  [-125.34871  -126.2704   -135.09479  ... -132.31728  -135.2544\n",
      "   -127.65115 ]\n",
      "  [-136.60023  -137.38039  -146.55562  ... -148.29782  -147.21555\n",
      "   -139.56773 ]]], shape=(1, 4, 50257), dtype=float32)\n",
      "logits:\n",
      " tf.Tensor([[-136.60023 -137.38039 -146.55562 ... -148.29782 -147.21555 -139.56773]], shape=(1, 50257), dtype=float32)\n",
      "logits[-1]:\n",
      " tf.Tensor([-136.60023 -137.38039 -146.55562 ... -148.29782 -147.21555 -139.56773], shape=(50257,), dtype=float32)\n",
      "probas:\n",
      " tf.Tensor(\n",
      "[[1.6012504e-03 7.3391170e-04 7.6013585e-08 ... 1.3312578e-08\n",
      "  3.9290576e-08 8.2355182e-05]], shape=(1, 50257), dtype=float32)\n",
      "idx_next:\n",
      " tf.Tensor([2651], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = tf.constant([[6109 , 3626, 6100,  345]])\n",
    "print(idx)\n",
    "# print(idx[:, -1, :])\n",
    "# generate(gpt2, idx=idx, max_new_tokens=3, context_size=256)\n",
    "logits = gpt2(idx)\n",
    "print(\"logits:\\n\", logits)\n",
    "logits = logits[:, -1, :]\n",
    "print(\"logits:\\n\", logits)\n",
    "print(\"logits[-1]:\\n\", logits[-1])\n",
    "probas = tf.nn.softmax(logits, -1)\n",
    "print(\"probas:\\n\", probas)\n",
    "idx_next = tf.argmax(probas, -1)\n",
    "print(\"idx_next:\\n\", idx_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8eaf98b0-74ca-4d40-8216-a2405a6a0eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids: tf.Tensor([[6109 3626 6100  345]], shape=(1, 4), dtype=int32)\n",
      "Every effort moves you\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    # encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    encoded_tensor = tf.constant(encoded) #.unsqueeze(0) # add batch dimension\n",
    "    encoded_tensor = tf.expand_dims(encoded_tensor, axis=0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    # flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    # return tokenizer.decode(flat.tolist())\n",
    "    return tokenizer.decode(token_ids[-1])\n",
    "\n",
    "token_ids = text_to_token_ids(\"Every effort moves you\", tokenizer)\n",
    "print(\"token_ids:\", token_ids)\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65e6f95d-43cc-45ab-b3f5-4a53456a72aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you forward.\n",
      "\n",
      "The first step is to understand\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=gpt2,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=256\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
