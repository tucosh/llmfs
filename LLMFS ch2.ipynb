{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211966b2-c71f-45a2-8526-04fdbeca8b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:28:12.409994Z",
     "iopub.status.busy": "2025-08-24T03:28:12.409539Z",
     "iopub.status.idle": "2025-08-24T03:28:12.414630Z",
     "shell.execute_reply": "2025-08-24T03:28:12.413620Z",
     "shell.execute_reply.started": "2025-08-24T03:28:12.409959Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f52ae7d-5b1a-4b66-8a7c-7de6aacef331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:28:14.375798Z",
     "iopub.status.busy": "2025-08-24T03:28:14.375508Z",
     "iopub.status.idle": "2025-08-24T03:28:14.379918Z",
     "shell.execute_reply": "2025-08-24T03:28:14.379218Z",
     "shell.execute_reply.started": "2025-08-24T03:28:14.375774Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hia\n"
     ]
    }
   ],
   "source": [
    "print('hia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b19e19e-b1c6-460d-b9e4-a7770a0c3d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:28:37.454096Z",
     "iopub.status.busy": "2025-08-24T03:28:37.453312Z",
     "iopub.status.idle": "2025-08-24T03:28:37.458013Z",
     "shell.execute_reply": "2025-08-24T03:28:37.457061Z",
     "shell.execute_reply.started": "2025-08-24T03:28:37.454071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeds = [\n",
    "    [0.43, 0.15, 0.89], # Your \n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts\n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55]  # step\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41522242-7857-465d-b765-7cfd38c5271c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:28:39.154871Z",
     "iopub.status.busy": "2025-08-24T03:28:39.153832Z",
     "iopub.status.idle": "2025-08-24T03:28:39.278345Z",
     "shell.execute_reply": "2025-08-24T03:28:39.277648Z",
     "shell.execute_reply.started": "2025-08-24T03:28:39.154846Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4300, 0.1500, 0.8900],\n",
       "        [0.5500, 0.8700, 0.6600],\n",
       "        [0.5700, 0.8500, 0.6400],\n",
       "        [0.2200, 0.5800, 0.3300],\n",
       "        [0.7700, 0.2500, 0.1000],\n",
       "        [0.0500, 0.8000, 0.5500]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor(embeds)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6924bf6-8a60-47c3-b56b-fa6a2271bdee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:28:42.748657Z",
     "iopub.status.busy": "2025-08-24T03:28:42.747811Z",
     "iopub.status.idle": "2025-08-24T03:28:42.777077Z",
     "shell.execute_reply": "2025-08-24T03:28:42.776459Z",
     "shell.execute_reply.started": "2025-08-24T03:28:42.748634Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores_2: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
      "attn_weights_2: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "row num: 0 weight: tensor(0.1385) row: tensor([0.4300, 0.1500, 0.8900]) weighted row: tensor([0.0596, 0.0208, 0.1233])\n",
      "row num: 1 weight: tensor(0.2379) row: tensor([0.5500, 0.8700, 0.6600]) weighted row: tensor([0.1308, 0.2070, 0.1570])\n",
      "row num: 2 weight: tensor(0.2333) row: tensor([0.5700, 0.8500, 0.6400]) weighted row: tensor([0.1330, 0.1983, 0.1493])\n",
      "row num: 3 weight: tensor(0.1240) row: tensor([0.2200, 0.5800, 0.3300]) weighted row: tensor([0.0273, 0.0719, 0.0409])\n",
      "row num: 4 weight: tensor(0.1082) row: tensor([0.7700, 0.2500, 0.1000]) weighted row: tensor([0.0833, 0.0270, 0.0108])\n",
      "row num: 5 weight: tensor(0.1581) row: tensor([0.0500, 0.8000, 0.5500]) weighted row: tensor([0.0079, 0.1265, 0.0870])\n",
      "context_vec_2: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "# attn_scores_2 is row 1 (\"journey\") dotted with each other row \n",
    "for i, x_i in enumerate(inputs):\n",
    "    # print(i, x_i)\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "print(\"attn_scores_2:\", attn_scores_2)\n",
    "# attn_weights_2 is softmax of attn_scores_2\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"attn_weights_2:\", attn_weights_2)\n",
    "context_vec_2 = torch.zeros(query.shape) # tensor([0., 0., 0.])\n",
    "# weight every input row by its attention weight\n",
    "for i, x_i in enumerate(inputs):\n",
    "    print(\"row num:\", i, \"weight:\", attn_weights_2[i], \"row:\", x_i, \"weighted row:\", attn_weights_2[i] * x_i)\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "print(\"context_vec_2:\", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f213eaa-fc5c-4617-b8fe-ce1d9c21c9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:28:47.011207Z",
     "iopub.status.busy": "2025-08-24T03:28:47.010096Z",
     "iopub.status.idle": "2025-08-24T03:28:47.036330Z",
     "shell.execute_reply": "2025-08-24T03:28:47.035642Z",
     "shell.execute_reply.started": "2025-08-24T03:28:47.011177Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores:\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "attn_scores:\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "attn_weights:\n",
      " tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
      "all_context_vecs:\n",
      " tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6,6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "      attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(\"attn_scores:\\n\", attn_scores)\n",
    "# equivalently, using matrix multiplication:\n",
    "attn_scores = inputs @ inputs.T\n",
    "print(\"attn_scores:\\n\", attn_scores)\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(\"attn_weights:\\n\", attn_weights)\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "print(\"all_context_vecs:\\n\", all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261ceb3e-ceb1-4224-a456-15db4c31bc66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:28:51.601457Z",
     "iopub.status.busy": "2025-08-24T03:28:51.600308Z",
     "iopub.status.idle": "2025-08-24T03:28:58.147797Z",
     "shell.execute_reply": "2025-08-24T03:28:58.146938Z",
     "shell.execute_reply.started": "2025-08-24T03:28:51.601422Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb3821d-0bfe-4ee6-b629-536f5849d3a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:29:02.972856Z",
     "iopub.status.busy": "2025-08-24T03:29:02.972290Z",
     "iopub.status.idle": "2025-08-24T03:29:03.868015Z",
     "shell.execute_reply": "2025-08-24T03:29:03.867400Z",
     "shell.execute_reply.started": "2025-08-24T03:29:02.972831Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights:\n",
      " tf.Tensor(\n",
      "[[0.20983477 0.20058146 0.19814923 0.12422822 0.12204872 0.14515767]\n",
      " [0.13854757 0.23789129 0.23327403 0.1239916  0.10818187 0.15811361]\n",
      " [0.1390076  0.23692146 0.23260194 0.12420439 0.1108002  0.15646443]\n",
      " [0.1435269  0.20739442 0.20455202 0.14619222 0.12629524 0.17203921]\n",
      " [0.15261085 0.19583869 0.19749065 0.13668668 0.18785891 0.12951429]\n",
      " [0.13847117 0.21836372 0.2127594  0.14204757 0.09880637 0.18955176]], shape=(6, 6), dtype=float32)\n",
      "all_context_vecs:\n",
      " tf.Tensor(\n",
      "[[0.44205943 0.59309864 0.57898915]\n",
      " [0.44186574 0.651482   0.56830883]\n",
      " [0.44312754 0.6495946  0.5670731 ]\n",
      " [0.43038973 0.6298281  0.55102706]\n",
      " [0.46710175 0.59099275 0.5265966 ]\n",
      " [0.4177245  0.6503232  0.5645352 ]], shape=(6, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# queries, keys and values are all the same matrix?\n",
    "queries = np.array(embeds)\n",
    "keys = np.array(embeds)\n",
    "values = np.array(embeds)\n",
    "\n",
    "# attn_scores = np.matmul(embeds, keys.T)\n",
    "attn_scores = tf.matmul(embeds, keys.T)\n",
    "\n",
    "attn_weights = tf.keras.activations.softmax(attn_scores, axis=1)\n",
    "print(\"attn_weights:\\n\", attn_weights)\n",
    "all_context_vecs = tf.matmul(attn_weights, keys)\n",
    "print(\"all_context_vecs:\\n\", all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c5e02ae-32c8-4b7a-9f75-a8c555a30c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:29:07.621263Z",
     "iopub.status.busy": "2025-08-24T03:29:07.620016Z",
     "iopub.status.idle": "2025-08-24T03:29:07.637954Z",
     "shell.execute_reply": "2025-08-24T03:29:07.636586Z",
     "shell.execute_reply.started": "2025-08-24T03:29:07.621234Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_2: tensor([0.5500, 0.8700, 0.6600])\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "print(\"x_2:\", x_2)\n",
    "d_in = inputs.shape[1] # input embedding size = 3\n",
    "d_out = 2\n",
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b710837-c160-4247-86fc-7acf08f9d61c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:29:23.368753Z",
     "iopub.status.busy": "2025-08-24T03:29:23.368429Z",
     "iopub.status.idle": "2025-08-24T03:29:23.380979Z",
     "shell.execute_reply": "2025-08-24T03:29:23.380068Z",
     "shell.execute_reply.started": "2025-08-24T03:29:23.368726Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0842f4cf-3072-46a9-bc78-1df76d23f323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:29:25.464160Z",
     "iopub.status.busy": "2025-08-24T03:29:25.463845Z",
     "iopub.status.idle": "2025-08-24T03:29:25.472099Z",
     "shell.execute_reply": "2025-08-24T03:29:25.471240Z",
     "shell.execute_reply.started": "2025-08-24T03:29:25.464136Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5500) tensor([0.2961, 0.5166])\n",
      "tensor(0.8700) tensor([0.2517, 0.6886])\n",
      "tensor(0.6600) tensor([0.0740, 0.8665])\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(x_2):\n",
    "  print(v, W_query[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552d00f2-e283-4435-be07-921530cb7d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:29:27.255781Z",
     "iopub.status.busy": "2025-08-24T03:29:27.255471Z",
     "iopub.status.idle": "2025-08-24T03:29:27.261740Z",
     "shell.execute_reply": "2025-08-24T03:29:27.260987Z",
     "shell.execute_reply.started": "2025-08-24T03:29:27.255758Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae013de-0ffe-42ae-9b3a-8eb726e68e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:32:40.959992Z",
     "iopub.status.busy": "2025-08-24T03:32:40.958911Z",
     "iopub.status.idle": "2025-08-24T03:32:40.969790Z",
     "shell.execute_reply": "2025-08-24T03:32:40.968424Z",
     "shell.execute_reply.started": "2025-08-24T03:32:40.959956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores_2: tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "attn_weights_2:\n",
      " tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "context_vec_2:\n",
      " tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "for i, key_i in enumerate(keys):\n",
    "    # print(i, x_i)\n",
    "    attn_scores_2[i] = torch.dot(key_i, query_2)\n",
    "print(\"attn_scores_2:\", attn_scores_2)\n",
    "d_k = keys.shape[-1] # 2\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1) # scale by 1/1.414\n",
    "print(\"attn_weights_2:\\n\", attn_weights_2)\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(\"context_vec_2:\\n\", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a913b4-73be-4051-9b08-2d86109200f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:47:03.337875Z",
     "iopub.status.busy": "2025-08-24T03:47:03.337312Z",
     "iopub.status.idle": "2025-08-24T03:47:03.343425Z",
     "shell.execute_reply": "2025-08-24T03:47:03.342428Z",
     "shell.execute_reply.started": "2025-08-24T03:47:03.337853Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "    def forward(self, x):\n",
    "        queries = x @ self.W_query\n",
    "        keys = x @ self.W_key\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**.5, dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6844b08a-17aa-41a9-9915-60d02fe20d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T03:48:29.627889Z",
     "iopub.status.busy": "2025-08-24T03:48:29.627275Z",
     "iopub.status.idle": "2025-08-24T03:48:29.643510Z",
     "shell.execute_reply": "2025-08-24T03:48:29.642647Z",
     "shell.execute_reply.started": "2025-08-24T03:48:29.627863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out) # 3,2\n",
    "print(sa_v1(inputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
