{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7095140a-e3ec-43c8-a732-a679abe26c32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "!pip install -q tiktoken\n",
    "from utils import load_gpt2_params_from_tf_ckpt\n",
    "from utils import tldr\n",
    "from utils import text_to_token_ids\n",
    "from utils import token_ids_to_text\n",
    "from utils import generate_text_simple\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e095182-3728-439d-93eb-012722a5a7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gpt2u import GPT2u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54318ad9-2111-42cd-b33a-78cd122ac529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_effort = tf.constant([[6109, 3626, 6100, 345]])\n",
    "config124M = {'n_embd': 768, 'n_vocab': 50257, 'n_ctx': 1024, 'n_layer': 12, 'n_head': 12}\n",
    "gpt2u=GPT2u(config124M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b70c1-bc70-4065-a82e-d0f83bc7e433",
   "metadata": {},
   "source": [
    "### First test with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a3b07cd-0a03-4046-bfa4-52a65a98cf61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. final logits: float32 (1, 4, 50257) [-44.049656 -20.970324 -23.276432]\n",
      ".. final logits: float32 (1, 4, 50257) [-44.049656 -20.970324 -23.276432]\n",
      ".. final logits: float32 (1, 5, 50257) [-44.049656 -20.970324 -23.276432]\n",
      ".. final logits: float32 (1, 6, 50257) [-44.049652 -20.970324 -23.276432]\n",
      ".. final logits: float32 (1, 7, 50257) [-44.049652 -20.970324 -23.276432]\n",
      ".. final logits: float32 (1, 8, 50257) [-44.04966  -20.970287 -23.276419]\n",
      ".. final logits: float32 (1, 9, 50257) [-44.04966  -20.970287 -23.276419]\n",
      ".. final logits: float32 (1, 10, 50257) [-44.04965  -20.97031  -23.276417]\n",
      ".. final logits: float32 (1, 11, 50257) [-44.04965  -20.97031  -23.276417]\n",
      ".. final logits: float32 (1, 12, 50257) [-44.04965  -20.97031  -23.276417]\n",
      ".. final logits: float32 (1, 13, 50257) [-44.04965  -20.97031  -23.276417]\n",
      "Output text:\n",
      " Every effort moves younc Brune pioneerSw Summon MB 40 directory Hay comply\n"
     ]
    }
   ],
   "source": [
    "y = gpt2u(x_effort)\n",
    "assert y.shape == [1, 4, 50257]\n",
    "assert np.allclose(y[0][0][:3], np.array([-44.049656 , -20.970324 , -23.276432]), rtol=1e-3, atol=1e-3)\n",
    "start_context = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=gpt2u,\n",
    "    idx=text_to_token_ids(start_context),\n",
    "    max_new_tokens=10,\n",
    "    # max_new_tokens=30,\n",
    "    context_size=256\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35170d08-cac6-4a77-af51-564137efbfda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir=\"openai_gpt2_weights/124M\"\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, config124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22a8f729-c8ee-42d7-b554-2f8724f475d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_weights_into_gpt2u(model, params):\n",
    "    model.embedding.word_embedding = tf.Variable(params['wte'], name=\"word_embedding\")\n",
    "    model.embedding.position_embedding = tf.Variable(params['wpe'], name=\"position_embedding\")\n",
    "\n",
    "    for b in range(12):\n",
    "        print(f\"loading block {b}\")\n",
    "        # Attention layer_norm\n",
    "        model.transformer.blocks[b].attention.layer_norm.beta = tf.Variable(params[\"blocks\"][b][\"ln_1\"][\"b\"], name=f\"transformer.blocks-{b}.attention.layer_norm.beta\")\n",
    "        model.transformer.blocks[b].attention.layer_norm.gamma = tf.Variable(params[\"blocks\"][b][\"ln_1\"][\"g\"], name=f\"transformer.blocks-{b}.attention.layer_norm.gamma\")\n",
    "\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        model.transformer.blocks[b].attention.self_attention.query_layer.w = tf.Variable(q_w, name=f\"transformer.blocks-{b}.attention.self_attention.query_layer.w\")\n",
    "        model.transformer.blocks[b].attention.self_attention.query_layer.b = tf.Variable(q_b, name=f\"transformer.blocks-{b}.attention.self_attention.query_layer.b\")\n",
    "        model.transformer.blocks[b].attention.self_attention.key_layer.w = tf.Variable(k_w, name=f\"transformer.blocks-{b}.attention.self_attention.key_layer.w\")\n",
    "        model.transformer.blocks[b].attention.self_attention.key_layer.b = tf.Variable(k_b, name=f\"transformer.blocks-{b}.attention.self_attention.key_layer.b\")\n",
    "        model.transformer.blocks[b].attention.self_attention.value_layer.w = tf.Variable(v_w, name=f\"transformer.blocks-{b}.attention.self_attention.value_layer.w\")\n",
    "        model.transformer.blocks[b].attention.self_attention.value_layer.b = tf.Variable(v_b, name=f\"transformer.blocks-{b}.attention.self_attention.value_layer.b\")\n",
    "        model.transformer.blocks[b].attention.projection.w = tf.Variable(params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"], name=f\"transformer.blocks-{b}.attention.projection.w\")\n",
    "        model.transformer.blocks[b].attention.projection.b = tf.Variable(params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"], name=f\"transformer.blocks-{b}.attention.projection.b\")\n",
    "\n",
    "        model.transformer.blocks[b].mlp.layer_norm.beta = tf.Variable(params[\"blocks\"][b][\"ln_2\"][\"b\"], name=f\"transformer.blocks-{b}.mlp.layer_norm.beta\")\n",
    "        model.transformer.blocks[b].mlp.layer_norm.gamma = tf.Variable(params[\"blocks\"][b][\"ln_2\"][\"g\"], name=f\"transformer.blocks-{b}.mlp.layer_norm.gamma\")\n",
    "        model.transformer.blocks[b].mlp.perceptron.w = tf.Variable(params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"], name=f\"transformer.blocks-{b}.mlp.perceptron.w\")\n",
    "        model.transformer.blocks[b].mlp.perceptron.b = tf.Variable(params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"], name=f\"transformer.blocks-{b}.mlp.perceptron.b\")                \n",
    "        model.transformer.blocks[b].mlp.projection.w = tf.Variable(params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"], name=f\"transformer.blocks-{b}.mlp.projection.w\")\n",
    "        model.transformer.blocks[b].mlp.projection.b = tf.Variable(params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"], name=f\"transformer.blocks-{b}.mlp.projection.b\")     \n",
    "    model.transformer.layer_norm.beta = tf.Variable(params[\"b\"], name=\"transformer.layer_norm.beta\")\n",
    "    model.transformer.layer_norm.gamma = tf.Variable(params[\"g\"], name=\"transformer.layer_norm.gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49427912-5db6-4c10-97f0-47fa384fcebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading block 0\n",
      "loading block 1\n",
      "loading block 2\n",
      "loading block 3\n",
      "loading block 4\n",
      "loading block 5\n",
      "loading block 6\n",
      "loading block 7\n",
      "loading block 8\n",
      "loading block 9\n",
      "loading block 10\n",
      "loading block 11\n"
     ]
    }
   ],
   "source": [
    "load_weights_into_gpt2u(gpt2u, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60beb1db-03c9-4eb8-aa96-ed4e4b60cc64",
   "metadata": {},
   "source": [
    "### Validate embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36f84b27-bf95-4fdc-b128-2d1e88df79bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_effort = tf.constant([[6109, 3626, 6100, 345]])\n",
    "x_effort_emb = gpt2u.embedding(x_effort)\n",
    "assert x_effort_emb.shape == [1, 4, 768]\n",
    "assert np.allclose(x_effort_emb[0][0][:3], np.array([0.07927368, -0.2979193 ,  0.08817437]), rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6f336-3b38-4b15-89c2-5708504abb50",
   "metadata": {},
   "source": [
    "### Validate attention.layer_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11805798-d838-4a05-a78e-89919ef37fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = gpt2u.transformer.blocks[0].attention.layer_norm(x_effort_emb)\n",
    "assert y.shape == [1, 4, 768]\n",
    "assert np.allclose(y[0][0][:3], np.array([0.047223  , -0.11664161, -0.02536647]), rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1979b-1438-4877-87e0-2dbb28a8d64e",
   "metadata": {},
   "source": [
    "### Validate attention.self_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5953c4c5-a6fe-4ed8-b3bb-a772a69ac864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = gpt2u.transformer.blocks[0].attention.self_attention(x_effort_emb)\n",
    "assert y.shape == [1, 4, 768]\n",
    "assert np.allclose(y[0][0][:3], np.array([0.28434375, -0.00881347,  0.34210888]), rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e90d7-bdf1-4314-8cf4-40802229e0ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validate attention.projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dba1ff10-4001-4e20-ab64-1820d4526701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = gpt2u.transformer.blocks[0].attention.projection(x_effort_emb)\n",
    "assert y.shape == [1, 4, 768]\n",
    "assert np.allclose(y[0][0][:3], np.array([2.5602593 ,  0.34704542,  0.3729586]), rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb95bb-aeff-435c-a158-1ba99e4f92ba",
   "metadata": {},
   "source": [
    "### Validate attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3064ce3c-4c75-4eb7-9757-25bbdba9ca5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = gpt2u.transformer.blocks[0].attention(x_effort_emb)\n",
    "tldr(y)\n",
    "assert y.shape == [1, 4, 768]\n",
    "assert np.allclose(y[0][0][:3], np.array([5.4214954e-01, -1.1554953e-01,  2.5736535e-01]), rtol=1e-2, atol=1e-2) # I loosened this!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa9aa7-5703-44ea-bba8-0c40170db1fb",
   "metadata": {},
   "source": [
    "### Validate mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27cb0179-3323-498c-85fe-ab15f8503998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = gpt2u.transformer.blocks[0].mlp(x_effort_emb)\n",
    "assert y.shape == [1, 4, 768]\n",
    "assert np.allclose(y[0][0][:3], np.array([3.2065992,   2.262373 ,   1.4517794]), rtol=1e-2, atol=1e-2) # had to loosen !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f77776e-22c5-49de-85f8-2955021444d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34801a91-97c3-4399-a390-d5c1016aa6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_effort = tf.constant([[6109, 3626, 6100, 345]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067e660-edf3-43d9-bac9-3812e6ee8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validate the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e01e497-c1d1-4fbe-b4c8-c121da80f097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. final logits: float32 (1, 4, 50257) [-35.521214 -34.924126 -38.39469 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'float32 (1, 4, 50257) [-35.521214 -34.924126 -38.39469 ]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = gpt2u(x_effort)\n",
    "assert y.shape == [1, 4, 50257]\n",
    "assert np.allclose(y[0][0][:3], np.array([-35.521214, -34.924126, -38.39469]), rtol=1e-2, atol=1e-2)\n",
    "tldr(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d6a31f-352e-4c72-8ed1-677162e5fc5f",
   "metadata": {},
   "source": [
    "### Write out to checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb76e720-0512-4950-ab44-9b025d2a7f29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_checkpoint'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkp_path = \"my_checkpoint\"\n",
    "checkpoint = tf.train.Checkpoint(model=gpt2u)\n",
    "checkpoint.write(chkp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa79495-aa2d-484c-87aa-801eb542b492",
   "metadata": {},
   "source": [
    "### Reload checkpoint weights into new model gpt2z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c442ed85-0e34-4213-962f-c20a39552efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config124M = {'n_embd': 768, 'n_vocab': 50257, 'n_ctx': 1024, 'n_layer': 12, 'n_head': 12}\n",
    "gpt2z=GPT2u(config124M)\n",
    "checkpoint = tf.train.Checkpoint(model=gpt2z)\n",
    "checkpoint.restore(chkp_path)\n",
    "assert len(gpt2z.variables) == len(gpt2u.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66a45e-4c80-4c9b-8a08-ed65ca342a82",
   "metadata": {},
   "source": [
    "### Validate gpt2z works just like gpt2u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "309c773d-3b1e-4d3f-a12b-2929c89f23e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. final logits: float32 (1, 4, 50257) [-35.521214 -34.924126 -38.39469 ]\n"
     ]
    }
   ],
   "source": [
    "y = gpt2z(x_effort)\n",
    "assert y.shape == [1, 4, 50257]\n",
    "assert np.allclose(y[0][0][:3], np.array([-35.521214, -34.924126, -38.39469]), rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c257aaf-abde-4cf1-a6b4-217663c683a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. final logits: float32 (1, 4, 50257) [-35.521214 -34.924126 -38.39469 ]\n",
      ".. final logits: float32 (1, 5, 50257) [-35.521214 -34.924126 -38.39469 ]\n",
      ".. final logits: float32 (1, 6, 50257) [-35.521214 -34.924126 -38.3947  ]\n",
      ".. final logits: float32 (1, 7, 50257) [-35.521214 -34.924126 -38.3947  ]\n",
      ".. final logits: float32 (1, 8, 50257) [-35.521263 -34.924175 -38.394753]\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(gpt2z, idx=x_effort, max_new_tokens=5, context_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea7858d-cdc3-48b3-8146-733f9f383a42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.array_equal(token_ids.numpy(), np.array([[6109, 3626, 6100,  345, 2651,   13,  198,  198,  464]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c1477-1f95-47d8-b886-8182583ef4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "957e6536-815f-4a08-a4f9-07e44f7c3236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. final logits: float32 (1, 4, 50257) [-35.521214 -34.924126 -38.39469 ]\n",
      ".. final logits: float32 (1, 5, 50257) [-35.521214 -34.924126 -38.39469 ]\n",
      ".. final logits: float32 (1, 6, 50257) [-35.521214 -34.924126 -38.3947  ]\n",
      ".. final logits: float32 (1, 7, 50257) [-35.521214 -34.924126 -38.3947  ]\n",
      ".. final logits: float32 (1, 8, 50257) [-35.521263 -34.924175 -38.394753]\n",
      ".. final logits: float32 (1, 9, 50257) [-35.521263 -34.924175 -38.394753]\n",
      ".. final logits: float32 (1, 10, 50257) [-35.521236 -34.92415  -38.39473 ]\n",
      ".. final logits: float32 (1, 11, 50257) [-35.521236 -34.92415  -38.39473 ]\n",
      ".. final logits: float32 (1, 12, 50257) [-35.521236 -34.92415  -38.39473 ]\n",
      ".. final logits: float32 (1, 13, 50257) [-35.521236 -34.92415  -38.39473 ]\n",
      ".. final logits: float32 (1, 14, 50257) [-35.521236 -34.92415  -38.39473 ]\n",
      ".. final logits: float32 (1, 15, 50257) [-35.521236 -34.92415  -38.39473 ]\n",
      ".. final logits: float32 (1, 16, 50257) [-35.521236 -34.92415  -38.39473 ]\n",
      ".. final logits: float32 (1, 17, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 18, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 19, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 20, 50257) [-35.508015 -34.910355 -38.38145 ]\n",
      ".. final logits: float32 (1, 21, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 22, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 23, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 24, 50257) [-35.508015 -34.910355 -38.38145 ]\n",
      ".. final logits: float32 (1, 25, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 26, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 27, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 28, 50257) [-35.508015 -34.910355 -38.38145 ]\n",
      ".. final logits: float32 (1, 29, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 30, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 31, 50257) [-35.521255 -34.92417  -38.394745]\n",
      ".. final logits: float32 (1, 32, 50257) [-35.508015 -34.910355 -38.38145 ]\n",
      ".. final logits: float32 (1, 33, 50257) [-35.52122  -34.924095 -38.394726]\n",
      "Output text:\n",
      " Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work.\n",
      "\n",
      "The second step is to understand the importance of your work.\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=gpt2z,\n",
    "    idx=text_to_token_ids(start_context),\n",
    "    max_new_tokens=30,\n",
    "    # max_new_tokens=30,\n",
    "    context_size=256\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16e0dc17-af1a-42d1-920b-06021e7d6347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[16833,  3626,  6100]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_effort = tf.constant([[6109, 3626, 6100, 345]])\n",
    "text_to_token_ids(\"Every effort moves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "204972fb-feef-4fff-924c-9d6fe7896add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'every effort moves'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text([[16833,  3626,  6100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b827497-8c78-42c3-b4c2-4025b04c64c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text([[6109, 3626, 6100, 345]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cf90844-21e8-4d97-86a5-a0507f8f6d77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[  40, 1107,  588]], dtype=int32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids(\"I really like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e00d7d-1fb5-4f4c-a500-b87abbd118bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
